\documentclass[25pt]{sciposter}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}

\usepackage{amsthm}

\usepackage[dvipsnames,usenames,svgnames,table]{xcolor} 
\usepackage{lipsum}
\usepackage{epsfig}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[german]{babel}
\usepackage{geometry}
\usepackage{multicol}
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{wrapfig}
\usepackage{gensymb}

\usepackage{empheq}

\usepackage{pgfplots}
\pgfplotsset{width=11cm,compat=1.9}


% for nice tableas
\usepackage{booktabs}

\graphicspath{ {img/} }

\geometry{
 landscape,
 a1paper,
 left=5mm,
 right=50mm,
 top=5mm,
 bottom=50mm,
 }
\usepackage{array}   % for \newcolumntype macro
\newcolumntype{L}{>{$}m{5.5cm}<{$}} % math-mode version of "l" column type

%BEGIN LISTINGDEF





\newcommand*\widefbox[1]{\fbox{\hspace{2em}#1\hspace{2em}}}
\newcommand{\limm}{\lim\limits_{n \to \infty}}
\newcommand{\limx}[1]{\lim\limits_{x \to #1}}
\newlength\dlf  % Define a new measure, dlf
\newcommand\alignedbox[2]{
% Argument #1 = before & if there were no box (lhs)
% Argument #2 = after & if there were no box (rhs)
&  % Alignment sign of the line
{
\settowidth\dlf{$\displaystyle #1$}
    % The width of \dlf is the width of the lhs, with a displaystyle font
\addtolength\dlf{\fboxsep+\fboxrule}
    % Add to it the distance to the box, and the width of the line of the box
\hspace{-\dlf}
    % Move everything dlf units to the left, so that & #1 #2 is aligned under #1 & #2
\boxed{#1 #2}
    % Put a box around lhs and rhs
}
}
\usepackage{graphicx,url}

%BEGIN TITLE
\title{\huge{Analysis 2}}

\author{\large{David Zollikofer}}
%END TITLE

\usepackage{palatino}
%\usepackage{eulervm}
\usepackage{mathpazo}
% begin custom commands
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
%\newcommand{\cos}{\operatorname{cos}}
%\newcommand{\sin}{\operatorname{sin}}
%\newcommand{\exp}{\operatorname{exp}}

\newtheorem{thm}{Thm}[section]

\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\usepackage[framemethod=TikZ]{mdframed}
\newenvironment{method}[1]{\begin{mdframed}[backgroundcolor=blue!10,innertopmargin=15pt, innerbottommargin=15pt, nobreak=true]
		\textbf{#1 }
	}
	{ 
	\end{mdframed}
}

\newenvironment{important}{\begin{mdframed}[backgroundcolor=red!50,innertopmargin=15pt, innerbottommargin=15pt, nobreak=true]
		\Large
	}
	{ 
	\end{mdframed}
}

\newenvironment{lemma}{\begin{mdframed}[backgroundcolor=gray!50,innertopmargin=15pt, innerbottommargin=15pt, nobreak=true]
		\Large
	}
	{ 
	\end{mdframed}
}

\newenvironment{trick}[1]{\begin{mdframed}[backgroundcolor=PineGreen!50,innertopmargin=15pt, innerbottommargin=15pt, nobreak=true]
			\textbf{#1 }
	}
	{ 
	\end{mdframed}
}


\usepackage{todonotes}
\newcommand{\TODO}[1]{\todo[inline]{\Large TODO:  #1}}





\DeclarePairedDelimiter\abs{\left|}{\right|}%



\setlength\abovedisplayskip{0pt}

\renewcommand{\familydefault}{\rmdefault}

% end custom commands

\begin{document}





\maketitle


\begin{multicols}{3}



\section{Einführung}


\subsection*{Wichtige Ungleichungen}

\begin{method}{Bernoulli Ungleichung}
	Wenn $x\in \R$ mit $x > -1$ sowie $n \in \mathbb{Z}$ mit $n >0$, dann gilt:
	\begin{align*}
		\left(1 + x\right) ^n \geq 1 + nx
	\end{align*}
	\textit{Beweis:} per Induktion
\end{method}


\begin{method}{Cauchy Schwarz}
	$\forall x,y\in \R^n$ gilt $|\langle x,y\rangle| \leq ||x||\cdot||y||$.
\end{method}


\begin{method}{Komplexe Zahlen} ${\displaystyle \varphi =\arg(z)}$\\
\begin{empheq}[box=\fbox]{align*}
	z &= x + iy & z &= r(\cos(\phi) + i\sin(\phi)) & z &= re^{i\phi}
\end{empheq}
\begin{empheq}[box=\fbox]{align*}
x &= r \cos \phi &  y &= r\sin \phi & r &= \sqrt{x^2 + y^2} & \phi &= \arctan\left(\frac{y}{x}\right) 
\end{empheq}
\textsc{Division:} Es gilt $z^{-1} = \frac{\bar{z}}{||z||^2}$ wenn $z \not = 0$\\
\textsc{Polarform} Wenn \begin{align*}
z_1 &= r_1(\cos(\theta_1) + i\sin(\theta_1))\\
z_2 &= r_2(\cos(\theta_2) + i\sin(\theta_2))
\end{align*}
dann gilt: 
\begin{align*}
z_1 \cdot z_2 &= r_1 \cdot r_2 \left(\cos(\theta_1 + \theta_2) + i\sin(\theta_1 + \theta_2)\right)\\
\frac{z_1}{z_2} &= \frac{r_1}{r_2}\left(\cos(\theta_1 - \theta_2) + i\sin(\theta_1 - \theta_2)\right)
\end{align*}
Zudem folgt durch Induktion:
\begin{align*}
	z^n = r^n (\cos(n\theta) + i \sin(n \theta))
\end{align*}

\textbf{Komplexe Nullstellen:} Die $n$-te Wurzel von $x$ berechnen wir (es gibt $n$ davon):
\begin{align*}
	\sqrt[n]{z} &= \sqrt[n]{r} e^{i \left( \frac{\phi_0}{n} + \frac{2k\pi}{n}\right)}\\
	&= \sqrt[n]{r} \left(\cos\left( \frac{\phi_0}{n} + \frac{2k\pi}{n}\right) + i \sin\left( \frac{\phi_0}{n} + \frac{2k\pi}{n}\right)\right)
\end{align*}

\end{method}




% -------------------------- Grenzwerte --------------------------

\section*{Grenzwerte}
Wir sagen dass $f$ an der Stelle $a$ den Grenzwert $L\in \R$ hat, geschrieben $\lim\limits_{x \to a} f(x) = L$ falls $\forall \epsilon > 0 \ \exists \delta > 0 $ sodass für alle $|x-a|<\delta$ gilt $|f(x)-L|< \epsilon$




\subsubsection*{Wurzeltrick}
\begin{align*}
	\lim\limits_{x \to \infty } \left( \sqrt{x^2 + x} -x \right) &= \lim\limits_{x \to \infty } \left( \sqrt{x^2 + x} -x \right)  \cdot \frac{  -\sqrt{x^2 + x} -x  }{ -\sqrt{x^2 + x} -x }\\
	&= 	\lim\limits_{x \to \infty } \frac{- \sqrt{x^2 + x} ^2 + x^2}{ -\sqrt{x^2 + x} -x}\\
	&= 	\lim\limits_{x \to \infty } \frac{x^2 + x - x^2}{ \sqrt{x^2 + x} +x}\\
	&=  \lim\limits_{x \to \infty}  \frac{1}{\sqrt{1 + \frac{1}{x}} + 1} = \frac{1}{2}
\end{align*}



\begin{method}{Fundamentallimes}
	Oft kann man einen dieser Limits verwenden:
	\begin{align*}
		\lim\limits_{x \to \infty} \left(1 + \frac{1}{x}\right)^x &= e &  \lim\limits_{x \to 0} \frac{\sin(x)}{x} &= 1 \\
		\lim\limits_{n \to \infty} \frac{a^n}{n^n} &= 0 & 	\lim\limits_{n \to \infty} \sqrt[n]{n} &= 1\\
		\lim\limits_{n \to \infty} \sqrt[n]{a} &= 1  & 	\lim\limits_{n \to \infty} \frac{1}{\sqrt[n]{n!}} &= 0
	\end{align*}
\end{method}

\begin{method}{Bernoulli - de l’Hospital}
	Wenn wir zwei differenzierbare Funktionen $f$, $g$ haben mit $g'(a)\not = 0$ dann gilt falls:
	\begin{itemize}
		\item entweder $\lim_{x \to a} f(x) = \lim_{x \to a} g(x) = 0 $
		\item oder $\lim_{x \to a} f(x) = \lim_{x \to a} g(x) = \infty $
	\end{itemize}
	dann gilt:
	\begin{equation*}
	\lim_{x \to a} \frac{f(x)}{g(x)} = 	\lim_{x \to a} \frac{f'(x)}{g'(x)}
	\end{equation*}
\end{method}
\begin{itemize}
	\item \textbf{Typ 1: $\frac{0}{0}$ oder $\frac{\infty}{\infty}$}\\
	
	\item \textbf{Typ 2: $0 \cdot \infty$} Wenn wir einen Grenzwert wie $\lim\limits_{x \to a} f(x)g(x)$ haben dann können wir den umformen in:
	\begin{align*}
	\lim_{x \to a}f(x) g(x) &= \lim_{x\to a} \frac{f(x)}{\frac{1}{g(x)}}\\
	\lim_{x \to a}f(x) g(x) &= \lim_{x\to a} \frac{g(x)}{\frac{1}{f(x)}}
	\end{align*}

	
	
	\item \textbf{Typ 3: $f(x)^{g(x)}$} Wenn wir Grenzwerte des Types $ \limx{a} f(x)^{g(x)}$ haben, dann schreiben wir es wie folgt:
	\begin{align*}
	\limx{a} f(x)^{g(x)} &= \limx{a} e^{\ln(f(x))\cdot g(x)} = e^{\limx{a} \ln(f(x))\cdot g(x)}
	\end{align*}

\end{itemize}

\subsection*{Taylor (als letzte Hoffung)}


% -------------------------- Folgen --------------------------

\section*{Folgen}

\begin{method}{Definition Konvergenz}
Folge $a_n$ is konvergent, falls $\exists l \in \mathbb{R}$ so dass $\forall \epsilon > 0$ die Menge $\{n \in \mathbb{N}^+: a_n \not \in (l-\epsilon, l + \epsilon)\}$ endlich ist. \\
Äquivalent: $\forall \epsilon > 0 \ \exists N \in \N $ so dass $ \forall n \geq N$ gilt $|a_n - l|< \epsilon$.
\end{method}

% -------------------------- Stetigkeit --------------------------


\section{Stetigkeit}
\begin{method}{Definition (Stetigkeit)}
	\begin{itemize}
		\item Sei $D \subseteq \mathbb{R}$, $x_0 \in D$. Die Funktion $f:D \to \R$ \textit{ist in $x_0$ stetig}, falls $\forall \epsilon > 0 \ \exists \delta > 0$, so dass für alle $x$ die Implikation $$|x-x_0| < \delta \implies |f(x) - f(x_0)| < \epsilon$$
		
		\item Daraus leitet sich ab: Sei $x_0 \in D \subseteq \R$ und $f:D \to \R$, $f$ ist genau dann in $x_0$ stetig, falls für \textbf{jede} Folge $(a_n)_{n \geq 1}$ in $D$ die Implikation gilt:$$\lim\limits_{n \to \infty} a_n = x_0 \implies \limm f(a_n) = f(x_0)$$
	\end{itemize}

\end{method}



\begin{method}{  Zwischenwertsatz (Bolzano)} 
	Sei $I \in \R$ ein Intervall, $f: I \to \R$ eine stetige Funktion und $a,b \in I$. Dann gilt: Für alle $c$ zwischen $f(a)$ und $f(b)$ exisitert ein $z$ zwischen $a$ und $b$ so dass $f(z) = c$.
\end{method}

\textbf{Beispiel (Zwischenwertsatz)}
\begin{itemize}
	\item Hat $e^{2x} - \log (1+x) = 2$ eine Lösung in $[0,1]$?. Wir def. $h(x) = e^{2x} - \log (1+x) -2$. Bemerke $h(x)$ ist stetig. Es gilt $h(0) = 1 - 0 - 2 = -1$, sowie $h(1) = e^2 - \log(2) -2 \geq 0$. Somit existiert $x_0 \in [0,1]$ mit $h(x_0) = 0$. Somit exisiter Lösung in $[0,1]$.
\end{itemize}


\begin{method}{Kompaktheit}
	Wir nennen ein Intervall $I \subseteq R$ kompakt, wenn es die Form $[a,b], a \leq b$ hat.
\end{method}



\section*{Exponentialfunktion \& Sinus \& Kosinus}

\begin{align*}
	\operatorname{exp}(x) &:=\sum_{n=0}^{\infty} \frac{x^n}{n!} = 1 + x + \frac{x^2}{2!} + \frac{x^3}{3!} + \frac{x^4}{4!} +  \ldots = \lim_{n \to \infty} \left( 1 + \frac xn \right)^n\\
	\operatorname{sin}(x) &:=\sum_{n=0}^{\infty} \frac{(-1)^n z^{2n+1}}{(2n+1)!} = x - \frac{x^3}{3!}+ \frac{x^5}{5!} - \frac{x^7}{7!} +  \frac{x^9}{9!} - \ldots\\
	\operatorname{cos}(x) &:=\sum_{n=0}^{\infty} \frac{(-1)^n x^{2n}}{(2n)!} = 1 - \frac{x^2}{2!} + \frac{x^4}{4!} -\frac{x^6}{6!} + \frac{x^8}{8!} -\ldots 
\end{align*}
Dabei gilt:
\begin{align*}
\operatorname{exp}(iz) &= \cos (z) + i\sin(z) &  \cos(z) ^2 &+ \sin(z)^2 = 1\\
\cos(z) &= \cos(-z) & \sin (-z) &= - \sin(z) \\
\sin (z) &= \frac{e^{iz} - e^{-iz}}{2i} & \cos (z) &= \frac{e^{iz} + e^{-iz}}{2}\\
\sin(z+w) &= \sin(z) \cos(w) + \cos(z) \sin(w) \\
\cos(z + w) &= \cos(z) \cos(w) - \sin(z) \sin(w)\\
\sin(x) - \sin(y) &=  2 \sin \left(\frac{x-y}{2}\right) \cos \left(\frac{x+y}{2}\right)\\
\cos(x) - \cos(y) &= - 2 \sin \left(\frac{x-y}{2}\right) \sin \left(\frac{x+y}{2}\right)\\
\sin(2x) &= 2\sin(x)\cos(x) &  \cos(2x) &= 1 - 2\sin^2(x)
\end{align*}

Zudem: $\sin(\arccos(t)) = \sqrt{1 - t^2}$ sowie $\cos(\arcsin(t)) = \sqrt{1-t^2}$

\begin{tikzpicture}
\begin{axis}[
clip=false,
xmin=-pi,xmax=2*pi,
%axis lines=left,
%axis x line=middle,
%axis y line=left,
xtick={-3.14,-1.57,0,1.57,3.14,4.71,6.28},
xticklabels={$-\pi$,$-\frac{\pi}{2}$,$0$, $\frac{\pi}{2}$,$\pi$,$\frac{3}{2}\pi$,$2\pi$}
]
\addplot[domain=-1*pi:2*pi,samples=400,red]{sin(deg(x))};
\addlegendentry{$\sin(x)$}
\addplot[domain=-1*pi:2*pi,samples=400,blue]{cos(deg(x))};
\addlegendentry{$\cos(x)$}
\end{axis}
\end{tikzpicture}


\subsection*{Einige Trigonometrische Ungleichungen}

\textbf{Zeige $\sin(x)$ monton auf $[-\frac{\pi}{2}, \frac{\pi}{2}]$} Es gilt bekanntlich $\sin(x) - \sin(y) =  2 \sin \left(\frac{x-y}{2}\right) \cos \left(\frac{x+y}{2}\right) \geq 0$ wenn $-\frac{\pi}{2} \leq y < x \leq \frac{\pi}{2}$ womit auch $\frac{x-y}{2} \in (0,\frac{\pi}{2}]$ und $\frac{x+y}{2} \in (- \frac{\pi}{2}, \frac{\pi}{2})$\\


\textbf{Zeige $\sin(x) < x$ für $x \geq 0$}
Wenn $x = 0$ dann folgt sofort $\sin(0) = 0$. Für $x\geq 1$ folgt auch $\sin(x) \leq 1 \leq x$. Es bleibt $x \in (0,1)$. Per Mittelwertsatz gibt es nun ein $c \in (0,x)$ für welches $\cos(c) = \frac{\sin(x) - \sin(0)}{x - 0}$. Daraus folgt $\frac{\sin(x)}{x} \leq 1$ was $\sin(x) \leq x$ impliziert.



\subsection*{Wertetabelle}



\begin{center}
	\begin{tabular}{ p{5cm} | p{5cm}  | p{5cm} | p{5cm}  }
		Value $\phi$ & $\sin(\phi)$ & $\cos(\phi)$ & $\tan(\phi)$ \\[0.75ex] \hline \hline 
		$0$ & $0$ & $1$ & $0$ \\  \hline
		$\frac{\pi}{12}$ & $\frac{\sqrt{3} -1}{2\sqrt{2}}$ & $\frac{1 + \sqrt{3}}{2\sqrt{2}}$ & $2 - \sqrt{3}$ \\ \hline
		$\frac{\pi}{6}$ & $\frac{1}{2}$ & $\frac{\sqrt{3}}{2}$ & $\frac{1}{\sqrt{3}}$	\\  \hline
		$\frac{\pi}{4}$ & $\frac{1}{\sqrt{2}}$ & $\frac{1}{\sqrt{2}}$ & $1$ \\  \hline
		$\frac{\pi}{3}$ & $\frac{\sqrt{3}}{2}$ & $\frac{1}{2}$ & $\sqrt{3}$\\  \hline
		$\frac{5\pi}{12}$ & $\frac{1 + \sqrt{3}}{2\sqrt{2}}$ & $\frac{\sqrt{3} - 1}{2\sqrt{2}}$ & $2 + \sqrt{3}$\\  \hline
		$\frac{\pi}{2}$ & $1$ & $0$ & $\infty$\\\hline
		$\frac{7\pi}{12}$ & $\frac{1+\sqrt{3}}{2\sqrt{2}}$ & $ -\frac{\sqrt{3}-1}{2\sqrt{2}}$ & $-2-\sqrt{3}$\\  \hline
		$\frac{2\pi}{3}$ & $\frac{\sqrt{3}}{2}$ & $- \frac{1}{2}$ & $-\sqrt{3}$\\ \hline
		$\frac{3\pi}{4}$ & $\frac{1}{\sqrt{2}}$ & $-\frac{1}{\sqrt{2}}$ & $-1$\\  \hline
		$\frac{5\pi}{6}$ & $\frac{1}{2}$ & $- \frac{\sqrt{3}}{2}$ & $- \frac{1}{\sqrt{3}}$ \\ \hline
		$\frac{11\pi}{12}$ & $\frac{\sqrt{3} -1}{2\sqrt{2}}$ & $-\frac{1+\sqrt{3}}{2\sqrt{2}}$ & $\sqrt{3} -2$\\ \hline
		$\pi$ & $0$ & $-1$ & $0$ \\ \hline
		$\frac{13\pi}{12}$ & $-\frac{\sqrt{3} -1}{2\sqrt{2}}$ & $- \frac{1 + \sqrt{3}}{2\sqrt{2}}$ & $2 - \sqrt{3}$\\ \hline
		$\frac{7\pi}{6}$ & $-\frac{1}{2}$ & $-\frac{\sqrt{3}}{2}$ & $\frac{1}{\sqrt{3}}$\\ \hline
		$\frac{5\pi}{4}$ & $-\frac{1}{\sqrt{2}}$ & $-\frac{1}{\sqrt{2}}$ & $1$ \\ \hline
		$\frac{4 \pi}{3}$ & $- \frac{\sqrt{3}}{2}$ & $-\frac{1}{2}$ & $\sqrt{3}$\\  \hline
		$\frac{17\pi}{12}$ & $-\frac{1+\sqrt{3}}{2\sqrt{2}}$ & - $\frac{\sqrt{3}-1}{2\sqrt{2}}$ & $2+ \sqrt{3}$\\ \hline
		$\frac{3\pi}{2}$ & $-1$ & $0$ & $\infty$ \\ \hline
		$\frac{19\pi}{12}$ & $-\frac{1+\sqrt{3}}{2\sqrt{2}}$ & $\frac{\sqrt{3} -1}{2\sqrt{2}}$ & $-2-\sqrt{3}$\\ \hline
		$\frac{5\pi}{3}$ & $-\frac{\sqrt{3}}{2}$ & $\frac{1}{2}$ & $-\sqrt{3}$\\ \hline
		$\frac{7\pi}{4}$ & $-\frac{1}{\sqrt{2}}$ & $\frac{1}{\sqrt{2}}$ & $-1$\\  \hline
		$\frac{11\pi}{6}$ & $- \frac{1}{2}$ & $\frac{\sqrt{3}}{2}$ & $- \frac{1}{\sqrt{3}}$\\  \hline
		$\frac{23\pi}{12}$ & $-\frac{\sqrt{3} - 1}{2\sqrt{2}}$ & $\frac{1+\sqrt{3}}{2\sqrt{2}}$ & $\sqrt{3} - 2$ \\  \hline
		$2\pi$ & $0$ & $1$ & $0$ \\  \hline
	\end{tabular}
\end{center}


\subsection*{Hyperbolische Funktionen}
\begin{align*}
\cosh(x) &= \frac{e^x + e^{-x}}{2}\\
\sinh(x) &= \frac{e^x - e^{-x}}{2}\\
\tanh(x) &= \frac{\sinh(x)}{\cosh(x)} = \frac{e^x - e^{-x}}{e^x + e^{-x}}
\end{align*}
Dies gibt die folgenden Zusammenhänge:
\begin{align*}
\cosh^2(x) - \sinh^2(x) &= 1\\
\cosh(x) + \sinh(x) &= e^x\\
\cosh(x) - \sinh(x) &= e^{-x}
\end{align*}

Sowie die Reihendarstellungen:

\begin{align*}
\sinh(z)&=z+{\frac {z^{3}}{3!}}+{\frac {z^{5}}{5!}}+{\frac {z^{7}}{7!}}+\dots =\sum _{n=0}^{\infty }{\frac {z^{2n+1}}{(2n+1)!}}\\
\cosh(z)&=1+{\frac {z^{2}}{2!}}+{\frac {z^{4}}{4!}}+{\frac {z^{6}}{6!}}+\dots =\sum _{n=0}^{\infty }{\frac {z^{2n}}{(2n)!}}
\end{align*}

Zudem gilt für $x \in (-1,1)$: $\operatorname{arctanh}(x) = \frac{1}{2} \ln \left( \frac{1+x}{1-x} \right)$





% -------------------------- Ableitung --------------------------




\section{Ableitung}

\begin{method}{Ableitung}
	Sei $D \subset \R$ , $f:D \to  \R$ und $x_0$ ein Häufungspunkt von $D$. $f$ ist in $x_0$ differenzierbar, falls der Grenzwert 
	$$ \lim\limits_{x \to x_0} \frac{f(x) -f(x_0)}{x-x_0}$$
	existiert. Ist dies der Fall, wird der Grenzwert mit $f'(x_0)$ bezeichnet.\\
	Alternativ nutzt man auch $x = x_0 + h$
	\begin{align*}
			f'(x_0) = \lim\limits_{h \to 0} \frac{f(x_0 + h) - f(x_0)}{h}
	\end{align*}
\end{method}


\begin{method}{Weierstrass (Äquivalente Definitionen)}
Sei $f : D \to \R$, $x_0$ ein Häufungspunkt von $D$, dann sind folgende Aussagen äquivalent:
\begin{enumerate}
	\item $f$ ist in $x_0$ differenzierbar.
	\item Es gibt ein $c\in \R$ und $r : D \cup \{x_0\} \to \R$ mit:
	\begin{enumerate}
		\item $f(x) = f(x_0) + c(x-x_0) + r(x) (x-x_0)$
		\item $r(x_0) = 0$ mit $r$ stetig in $x_0$
	\end{enumerate}
Falls dies zutrifft ist $c=f'(x_0)$ eindeutig bestimmt.
\end{enumerate}
\end{method}

\textbf{(Beispiel) Per Definition Ableiten}

\begin{itemize}
	\item $f(x) = x^2$:
	\begin{align*}
		\frac{f(x) - f(x_0)}{x-x_0} &= 	\frac{x^2 - x_{0}^2}{x-x_0} = \frac{(x-x_0) (x+x_0)}{x-x_0} = x + x_0\\
		\lim_{x \to x_0} \frac{f(x)-f(x_0)}{x-x_0} &= \lim_{(x\to x_0)} x + x_0 = 2x_0
	\end{align*}
\end{itemize}



\begin{method}{Satz von Rolle}
	Sei $f: [a,b] \to \R$ stetig auf $(a,b)$ differenzierbar. Falls $f(a) = f(b)$, dann gibt es $\xi \in [a,b]$ mit $f'(\xi) = 0$
\end{method}
\textbf{Beweis (Satz von Rolle)} Aus dem Min-Max Satz folgt $\exists u,v \in [a,b]$ mit $f(u) \leq f(x) \leq f(v) \ \forall x \in [a,b]$. Falls einer der beiden in $(a,b)$ liegt nennen wir es $\xi$. Sonst gilt $f(a) = f(b)$ und dann $\xi = a$.


\begin{method}{Satz von Lagrange / Mittelwertsatz}
	Sei $f:[a,b] \to \R$ stetig mit $(a,b)$ differenzierbar. Dann gibt es $\xi \in (a,b)$ mit $$f(b) - f(a) = f'(\xi) (b-a)$$
	Dieser Satz ist auch bekannt als Mittelwertsatz. Die Aussage ist äquivalent zu: 
	\begin{align*}
		\exists x \in (a,b) : \quad f'(x) = \frac{f(b) -f(a) }{b-a}
	\end{align*}
\end{method}
\textbf{Beispiele (Lagrange)}
\begin{itemize}
	\item \textit{Zeige $|\sin(a) - \sin(b)| \leq |b-a|$:} Es folgt direkt dass $\exists c$: $\frac{\sin(b)- \sin(a)}{b-a} = \cos(c)$. Es folgt: $\cos(c) (b-a) = \sin(b) - \sin(a)$. Da aber $\cos(c) \leq 1$ folgt:
	$|b-a| \geq |\sin(b) - \sin(a)|$.
	\item \textit{Beweise: falls $f'(x) = 0 \ \forall x$, dann ist $f(x)$ auf $[a,b]$ konstant:} Aus Lagrange folgt dass für $x_1,x_2\in (a,b)$ beliebig: $0 = \frac{f(x_2)-f(x_1)}{x_2-x_1}$ dies impliziert $f(x_1) = f(x_2)$ $\forall x_1,x_2 \in (a,b)$.
\end{itemize}


\begin{method}{Ableitung der Umkehrfunktion}
	Sei $f: D \to E$ eine bijektive Funktion, $x_0 \in D$ ein Häufungspunkt. Sei $f$ in $x_0$ differenzierbar und $f'(x_0) \not = 0$, dann ist $y_0$ ein Häufungspunkt von $E$, $f^{-1}(y_0)$ differenzierbar und es gilt
	\begin{align*}
		(f^{{-1}})'(y_0) &= {\frac  {1}{f'(f^{{-1}}(y_0))}}={\frac  {1}{f'(x_0)}}.
	\end{align*}
\end{method}

\textbf{Zweite Ableitung der Umkehrfunktion} $(f^{-1})''(y) = \left(\frac{1}{f' \circ f^{-1}}\right)(y)$ mit Kettenregel.  


\textbf{Beispiel (Ableitung der Umkehrfunktion)} Sei $f^{-1}(y) = \ln(y)$. Dann gilt $f(x) = e^x$, es folgt $f'(x)= e^x$ woraus $(f^{-1})'(y) = \frac{1}{f'(f^{-1}(y))}$ sowie $(f^{-1})'(y) = \frac{1}{y}$ folgt. 


\subsection*{Konvexität}

\begin{method}{Konvex}
	$f : I \to \R$ ist konvex (auf I) falls für alle $x \leq y$ $x,y \in I$ und $\lambda \in [0,1]$
	\begin{align*}
	f(\lambda x + (1-\lambda)y) \leq \lambda f(x) + (1-\lambda)f(y)
	\end{align*}
	Zudem gilt für $x_0 < x< x_1$ in $I$:
	\begin{align*}
	 \frac{f(x) - f(x_0)}{x-x_0} \leq \frac{f(x_1) - f(x)}{x_1 - x}
	\end{align*}
	Man beweist dies indem man $x = (1-\lambda) x_0 + \lambda x_1$ wählt und somit $\lambda = \frac{x-x_0}{x_1 - x_0}$
\end{method}

\section*{Taylorapproximation}

\begin{method}{Taylorapproximation}
Sei $f\in C^m ([a,b])$ auf $(a,b)$ $m+1$ mal differenzierbar. Dann exisitert $\xi \in (a,b)$ mit 
\begin{align*}
	f(x) =& f(a) + f'(a)(x-a) + \ldots + \frac{1}{m!} f^{(m)} (a) (x-a)^m\\ &+ \frac{1}{(m+1)!} f^{(m+1)}(\xi) (x-a)^{m+1}
\end{align*} 
 \textbf{Beziehungsweise:}\\
	Sei $f:[a,b] \to \R$ stetig und in $(a,b)$ (n+1) mal differenzierbar. Für jedes $a<x\leq b$ gibt es $\xi \in (a,x)$ mit
	\begin{align*}
	f(x) &= \sum_{k=0}^n \frac{f^{(k)}(a)}{k!} (x-a)^k + \frac{f^{(n+1)}(\xi)}{(n+1)!} (x-a)^{n+1}
	\end{align*}
Oder Alternativ $|R_N f(x;a)| \leq \sup\limits_{a < \xi < x} |f^{(n+1)} (\xi)|  \frac{(x-a)^{n+1}}{(n+1)!}$
\end{method}

\textbf{Beispiel (Taylorapproximation)}
\begin{itemize}
	\item \textit{Finde $P_3 ^0 (x)$ von $f(x) = \sin(x)e^x$} Wir berechnen zuerst die Ableitungen:
	\begin{align*}
	    f(x) &= \sin(x)e^x & f(0) &= 0\\
		f'(x) &= e^x (\sin(x) + \cos(x)) & f'(0) &= 1\\
		f''(x) &= 2e^x \cos(x) & f''(0) &= 2\\
		f'''(x) &= 2e^x (\cos(x) - \sin(x)) & f'''(0) &=2 \\
		f''''(x) &= -4e^x\sin(x)
	\end{align*} 
	Dies gibt uns: 
	\begin{align*}
		P_3 ^0 (x) &= f(0) + f'(0)\cdot x + \frac{f''(x)}{2!} x^2 + \frac{f'''(x)}{3!}x^3\\
		&= 0 + 1 \cdot x + \frac{1}{2} \cdot 2 \cdot x^2 + 2 \frac{1}{3!}x^3\\
		&= x + x^2 + \frac{x^3}{3}
	\end{align*}
	Nun wollen wir den Fehler abschätzen auf $[-\frac{1}{2},\frac{1}{2}]$:
	\begin{align*}
		|R_3 ^0 (x)| &= \left| \frac{-4e^c \sin(c)}{4!} x^4\right|\\
		&= \frac{e^c |\sin(c)|}{3!} x^4 \leq \frac{e^c}{3!} x^4
	\end{align*}
	Da nun $c \in (0,x)$ und $x \in [-\frac{1}{2}, \frac{1}{2}]$ folgt: $\frac{e^c}{3!} x^4 \leq \frac{e^{1/2}}{6}x^4$
	\item \textbf{Taylorreihe von $\frac{x^2}{2+x}$} Wir wissen dass $\frac{1}{1-x} = 1 + x + x^2 + \ldots = \sum_{n=0}^{\infty} x^n$ ist. Somit folgt:
	\begin{align*}
		\frac{x^2}{2+x} &= x^2 \frac{1}{2+x} = \frac{x^2}{2} \frac{1}{1 - (-\frac{x}{2})} \\
		&= \frac{x^2}{2} \left( 1 - \frac{x}{2} + \left(\frac{x}{2}\right)^2+ \ldots \right)\\
		&= \frac{x^2}{2} - \frac{x^3}{4} + \frac{x^4}{8} + \ldots = \sum_{n=0}^{\infty} \frac{(-1)^n x^{n+2}}{2^{n+1}}
	\end{align*}
\end{itemize}



\subsection*{Wichtige Taylorapproximationen um $x=0$}
\begin{itemize}
	\item $\boxed{\frac{1}{1-x}}$ Für alle $x \in (1,0)$ gilt:
	\begin{align*}
	{\frac{1}{1-x}} &= 1 + x + x^2 + x^3 + x^4 + \cdots \\
	&= \sum_{n=0}^{\infty} x^n
	\end{align*}	
	
	\item $\boxed{e^x}$ Für alle $x \in \R$ gilt:
	\begin{align*}
		e^x &= 1 + x + \frac{x^2}{2!} + \frac{x^3}{3!} + \frac{x^4}{4!}\\
		&= \sum_{n=0}^{\infty} \frac{x^n}{n!}
	\end{align*}
	
	\item $\boxed{\cos(x)}$ Für alle $x\in R$ gilt:
	\begin{align*}
	\cos(x) &= 1 - \frac{x^2}{2!} + \frac{x^4}{4!} - \frac{x^6}{6!} + \frac{x^8}{8!} - \cdots  \\
	&= \sum_{n=0}^{\infty} (-1)^n \frac{x^{2n}}{(2n)!}
	\end{align*}
	
	\item $\boxed{\sin(x)}$ Für alle $x\in R$ gilt:
	\begin{align*}
	\sin(x) &=  x - \frac{x^3}{3!} + \frac{x^5}{5!} - \frac{x^7}{7!} + \frac{x^9}{9!} - \cdots\\
	&= \sum_{n=0}^{\infty} (-1)^n \frac{x^{2n+1}}{(2n+1)!} = \sum_{n=1}^{\infty} (-1)^{(n-1)} \frac{x^{2n-1}}{(2n-1)!}
	\end{align*}

	\item $\boxed{\ln(1+x)}$ Für alle $x\in (-1,1]$ gilt:
	\begin{align*}
	\ln(x+1) &= x - \frac{x^2}{2} + \frac{x^3}{3} - \frac{x^4}{4} + \frac{x^5}{5}- \cdots \\
	&= \sum_{n=1}^{\infty} (-1)^{(n+1)} \frac{x^n}{n}
	\end{align*}

	\item $\boxed{\arctan(x)}$ Für alle $x\in [-1,1]$ gilt:
	\begin{align*}
	\arctan(x) &= x - \frac{x^3}{3} + \frac{x^5}{5} - \frac{x^7}{7} + \frac{x^9}{9} - \cdots \\
	&= \sum_{n=0}^{\infty} (-1)^n \frac{x^{2n+1}}{2n+1}
	\end{align*}

	\item $\boxed{(1 + x)^\alpha}$ Für alle $x\in \R$ gilt:
	\begin{align*}
	(1 + x)^\alpha &=  1 + \alpha x + \frac{\alpha(\alpha-1)}{2!} x^2 + \cdots \\
	 &= \sum_{k=0}^{\infty} \; {\alpha \choose k} \; x^k 
	\end{align*}
	
	\item $\boxed{\sinh(x)}$ Für alle $x\in \R$ gilt:
	\begin{align*}
	\sinh(x) &= x + \frac{x^3}{6} + \frac{x^5}{120} + \mathcal{O}(x^7)\\
	&= \sum_{k=0}^{\infty}\frac{x^{1+2k}}{(1+2k)!}
	\end{align*}
	
	\item $\boxed{\cosh(x)}$ Für alle $x\in \R$ gilt:
	\begin{align*}
	\cosh(x) &= 1 + \frac{x^2}{2} + \frac{x^4}{24} + \frac{x^6}{720} +  \mathcal{O}(x^7)\\
	&= \sum_{k=0}^{\infty}\frac{x^{2k}}{(2k)!}
	\end{align*}
	

\end{itemize}






\subsection*{Fundamentalsatz}
\begin{method}{Stammfunktion}
Die Funktion $F(x) = \int_{a}^{x} f(t) dt$ ist in $[a,b]$ stetig und differenzierbar mit $F' = f$ wenn $a<b$ und $f:[a,b]\to R$ stetig ist. \\
\textit{Beweis:} Aus additivität folgt: $\int_{a}^{x_0} f(t) dt$ + $\int_{x_0}^{x} f(t) dt = \int_{a}^{x} f(t) dt$. Also $F(x) - F(x_0) = \int_{x_0}^{x} f(t) dt$. Per Mittelwertsatz sehen wir nun, dass es ein $\xi \in [x,x_0]$ gibt mit $\int_{x_0}^{x} f(t) dt = f(\xi) (x-x_0) $. Für $x \not = x_0$ folgt somit $\frac{F(x) - F(x_0)}{x-x_0} = f(\xi)$. Wegen der Stetigkeit von $f$ folgt: $\lim_{(x\to x_0)} \frac{F(x) - F(x_0)}{x-x_0} = f(x_0)$. \qed
\end{method}


\begin{method}{Fundamentalsatz der Differentialrechnung}
Sei $f:[a,b] \to \R$ stetig. Dann gibt es eine Stammfunktion $F$ von $f$, die bis auf eine additive Konstante eindeutig bestimmt ist und es gilt:
$$\int_{a}^{b} f(x) dx = F(b) - F(a)$$
\textit{Beweis:} Existenz folgt aus Stammfunktionssatz. Seien $F_1, F_2$ Stammfkt., dann gilt $F_1' - F_2' = 0$. Somit ist $F_1 - F_2 = C$ mit $F(x) = C + \int_{a}^{x} f(t) dt$. Es folgt auch $F(a) = \int_{a}^{a} f(t) dt + C$ und somit $F(a) = C$. Es folgt daraus $F(b)-F(a) = \int_{a}^{b} f(t) dt$ \qed 
\end{method}


\subsection*{Ableitung des Integrals}
Mit der Kettenregel folgt aus dem Fundamentalsatz:
\begin{align*}
\frac{d}{dx} \left( \int_{u(x)}^{v(x)} f(t)  dt \right) &= f(v)\frac{dv}{dx} - f(u)\frac{du}{dx}
\end{align*}
\textbf{Beispiel:} Finde die Ableitung von $f(x) = \int_{x}^{2} \frac{e^{t^2}}{t} dt + \log(\frac{x}{2})$. Somit ist $f'(x) = -\frac{e^{x^2}}{x} + \frac{1}{x}$. Bemerke dass $f'(x) = \frac{1-e^{x^2}}{x}<0$ für $x \in (0, \infty)$ und somit umkehrbar.
Wir können auch das Taylorpolynom 1ter Ordnung von $f'^{-1}(x)$ um $x_0 = 0$ berechnen. Es gilt $f(2) = 0$, sowie $(f^{-1})'(0) = \frac{1}{f'(f^{-1}(0))} = \frac{1}{f'(2)} = \frac{2}{1-e^4}$.

\section*{Integrale Ausrechnen}

\begin{important}
Integrationskonstante $C$ nicht vergessen!
\end{important}

\subsection*{Elementare Integrale}
Siehe Tabelle

\subsection*{Direkte Integrale}
Diese sind vom Typ $\int f(g(x)) g'(x) dx = F(g(x))$.

\subsection*{Partielle Integration}
\begin{method}{Partielle Integration}
\begin{align*}
	\int f' \cdot g \ dx = f \cdot g - \int f \cdot g' \  dx
\end{align*}
\end{method}
\textbf{Beispiele}:


\subsection*{Integrale rationaler Funktionen}
\begin{method}{Partielle Integration}
	$$\int \frac{p(x)}{q(x)} dx$$
	Wenn nun $\deg(p) \geq \deg(q)$ dann machen wir eine Polynomdivision $p:q$, sonst mache eine Parzialbruchzerlegung
\end{method}

\subsection*{Substitutionsregel}
\begin{method}{Substitutionsregel}
Ist $f$ stetig und $g$ erfüllt:
\begin{align*}
	y = g(x) \iff x = g^{-1}(y)
\end{align*}
Dann gilt:
\begin{align*}
\int_a ^b f(g(x))g'(x) dx &= \int_{g(a)}^{g(b)} f(y) dy
\end{align*}
Als Merksatz gilt $dy = g'(x) dx$ respektive $dx = \frac{1}{t} dt$
\end{method}

\subsubsection*{Integrale der Form $\int F(e^x, \sinh(x), \cosh(x)) dx$}
Substituiere mit $e^x = t$, ($dx = \frac{1}{t} dt$)\\
\textbf{Beispiel:}
\begin{align*}
	\int \frac{e^{2x}}{e^x + 1} dx &= \int \frac{t^2}{t + 1 } \frac{1}{t} dt = \int\frac{t +1 - 1}{t+1} dt\\
	\int \frac{1}{\cosh(x)} dx &= \int \frac{1}{\frac{1}{2} (e^x + e^{-x})} dx = \int \frac{2}{t + \frac{1}{t}} \frac{1}{t} dt = \frac{2}{t^2 + 1} dt
\end{align*}

\subsubsection*{Integrale der Form $\int F(\log(x)) dx$}
Substituiere mit $\log(x) = t$, ($dx = e^t dt$)\\
\textbf{Beispiel:}
\begin{align*}
	\int (\log(x))^2 dx &= \int t^2 e^t dt = t^2 e^t - \int 2t e^t dt  \\
	&= x(\log(x))^2 -2x\log(x) + 2x + C
\end{align*}

\subsubsection*{Integrale der Form $\int F(\sqrt[\alpha]{Ax + B}) dx$}
Substituiere mit $t = \sqrt[\alpha]{Ax + B}$\\
\textbf{Beispiel:}
\begin{align*}
	\int \frac{1}{\sqrt{x} \sqrt{1-x}} &= \int \frac{1}{t \sqrt{1-t^2}} 2t dt = \int \frac{2}{\sqrt{1-t^2}}
\end{align*}

\subsubsection*{Integrale die $\sin, \cos, \tan$ in geraden Potenzen enthalten}
Substituiere mit $\tan(x) = t$, ($dx = \frac{1}{1+t^2} dt$). Es gilt zudem:

\begin{align*}
\sin^2(x) &= \frac{t^2}{1+t^2} & \cos^2(x) &= \frac{1}{1+t^2}
\end{align*}

\textbf{Beispiel:}
\begin{align*}
	\int \frac{1}{\sin^2(x) + 1} dx &= \int \frac{1}{\frac{t^2}{1+t^2} + 1} \frac{1}{t^2 + 1} dt = \int \frac{1}{1+2t^2} dt\\ &= \frac{1}{\sqrt{2}} \int  \frac{\sqrt{2}}{1 + (\sqrt{2}t)^2} dt = \frac{1}{\sqrt{2}} \arctan(\sqrt{2}t)
\end{align*}


\subsubsection*{Integrale die $\sin, \cos, \tan$ in ungeraden Potenzen enthalten}
Substituiere mit $\tan(\frac{x}{2}) = t$, ($dx = \frac{2}{1+t^2} dt$). Es gilt zudem:

\begin{align*}
\sin(x) &= \frac{2t}{1+t^2} & \cos(x) &= \frac{1-t^2}{1+t^2}
\end{align*}

\textbf{Beispiel:}
\begin{align*}
	\int \frac{1}{\cos(x)} dx &= \int \frac{1}{\frac{1-t^2}{1+t^2}} \frac{2}{1+t^2} dt = \int \frac{2}{1-t^2} dt
\end{align*}

\subsection*{Quadratisch Ergänzen}
\begin{method}{Quadratisch ergänzen} Für den Ausdruck $\sqrt{ax^2 + bx + x}$ definieren wie $\beta = - \frac{b}{2a}$. Es gibt nun zwei Optionen (mit dem Ziel $x= \alpha u + \beta$):

\begin{itemize}
	\item Falls $b^2 - 4ac > 0$. So setze $\alpha = \frac{\sqrt{b^2 - 4ac}}{2a}$. Dies gibt uns dann:
	\begin{align*}
		ax^2 + bx + c = \left(\frac{b^2 -4ac}{4a}\right)\left(u^2 - 1\right)
	\end{align*}
	
	\item Falls $b^2 - 4ac < 0$. So setze $\alpha = \frac{\sqrt{4ac - b^2}}{2a}$. Dies gibt uns dann:
	\begin{align*}
	ax^2 + bx + c = \left(\frac{4ac - b^2}{4a}\right)\left(u^2 + 1\right)
	\end{align*}
	Falls dies in einem Integral ist kann man nun mit $u=\sinh(t)$, $du = \cosh(t) dt$ ersetzen.
\end{itemize}

\end{method}

\begin{method}{Ekelhafte Zahlen}
	
	\begin{itemize}
	\item $\int \frac{1}{a^2 + x^2} dx$ lösen wir mit $x=a\cdot u$, $dx = a \ du$, dies gibt uns:
	\begin{align*}
		\int \frac{1}{a^2 + x^2} = \int\frac{1}{a^2 (1 + u^2)} a \ du = \frac{1}{a} \arctan(u) = \frac{1}{a} \arctan\left(\frac{x}{a}\right)
	\end{align*}
	
	\item $\int \sqrt{r^2 - x^2} dx$ lösen wir mit $x = r \sin \phi$, $dx = r \cos \phi \ d\phi$ :
	\begin{align*}
\int \sqrt{r^2 - x^2} dx = \int \sqrt{r^2 (1-\sin^2 \phi)} r \cos \phi \ d\phi = r^2 \int \cos^2(\phi) \ d\phi
\end{align*}
Wir können nun die Winkelverdopplungsregel anwenden.
	\end{itemize}
	
\end{method}

\subsubsection*{Integrale mit $\sqrt{Ax^2 + Bx + C}$ im Nenner}
Mithilfe quadratischer Ergänzung auf einen der folgenden Fälle zurückführen:
\begin{align*}
\int \frac{1}{\sqrt{1-x^2}} dx &= \arcsin(x) + C\\
\int \frac{1}{\sqrt{x^2-1}} dx &= \operatorname{arcosh}(x) + C\\
\int \frac{1}{\sqrt{1+x^2}} dx &= \operatorname{arcsinh}(x) + C
\end{align*}




\subsubsection*{Integrale mit $\sqrt{Ax^2 + Bx + C}$ im Zähler}
Mithilfe quadratischer Ergänzung auf einen der folgenden Fälle zurückführen, dann substituieren
\begin{align*}
\int {\sqrt{1-x^2}} dx \quad &\text{subsitution: } x = \sin(t) \Leftarrow dx = \cos(t) dt\\
\int {\sqrt{x^2-1}} dx \quad &\text{subsitution: } x = \cosh(t) \Leftarrow dx = \sinh(t) dt \\
\int {\sqrt{1+x^2}} dx \quad &\text{subsitution: } x = \sinh(t) \Leftarrow dx = \cosh(t) dt
\end{align*}


% -------------------------- Partialbruchzerlegung ------------------------------

\subsection*{Rationale Funktionen (Partialbruchzerlegung)}

Wenn wir $\frac{P(x)}{Q(x)}$ integrieren wollen und $\deg(P(x)) \geq \deg(Q(x))$, dann führen wir eine Polynomdivision durch:

\includegraphics[width=0.7\linewidth]{img/polyDiv.png}\\
Andernfalls machen wir eine Partialbruchzerlegung:

\begin{align*}
	\frac{t+2}{t^2(t^2 + 2)} &= \frac{A}{t^2} + \frac{B}{t} + \frac{Ct + D}{t^2 + 2}\\
	\frac{t}{t^3 + t^2 - t - 1} &= \frac{A}{(t+1)} + \frac{B}{(t+1)^2} + \frac{C}{t-1} \quad \text{first polyDiv}\\
	\frac{t^4 + 1}{(t^2 + 1)^2} &= 1 + \frac{-2t}{(t^2 + 1)^2} = 1 + \ldots + \frac{At + B}{t^2 + 1} + \frac{Ct + D}{(t^2 + 1)^2}
\end{align*}


% -------------------------- Uneigentliche Integrale --------------------------

\section*{Uneigentliche Integrale}


Es gibt zwei Arten von uneigentlichen Integralen, man interessiert sich dafür ob die Integrale konvergieren oder nicht. Für beide Arten braucht man die gleichen Techniken:

\begin{enumerate}
	\item[] \textbf{Typ 1:} $f(x)$ auf $[a,\infty)$ stetig. Dann setzt man $\int_{a}^{\infty} f(x) dx = \lim_{R \to \infty} \int_{a}^{R} f(x) dx$ falls der Grenzwert existiert.
	\item[] \textbf{Typ 2:} $f(x)$ auf $(a,b]$ stetig. Dann setzt man $\int_{a}^{b} f(x) dx= \lim_{\epsilon \to 0^+} \int_{a+\epsilon}^{b} f(x) dx$ falls der Grenzwert existiert.
\end{enumerate}


\subsection*{Definition + direkte Berechung}
Setze die Definition ein (replace $\infty$ with $R$) und berechne dann das Integral. Lasse nun $R$ nach $\infty$ laufen.

\subsection*{Vergleichskriterium}
 Seien $f,g$ auf dem Integrationsgebiet stetig mit $0 \leq f(x) \leq g(x)$ für alle $x$. Dann gilt:
 \begin{enumerate}
 	\item Ist $\int_{a}^{\infty} g(x) dx$ konvergent, so auch $\int_{a}^{\infty} f(x) dx$
 	\item Ist $\int_{a}^{\infty} f(x) dx$ divergent, so auch $\int_{a}^{\infty} g(x) dx$
 \end{enumerate}
 Oft braucht man $\int_{1}^{\infty} \frac{1}{x^p} dx$ als Vergleichsmittel welches für $p>1$ konvergiert, für $p \leq 1$ ist es divergent.\\
\textbf{Beispiel (Vergleich)} 
\begin{itemize}
	\item $\int_{1}^{\infty} \frac{1 + e^x}{x} dx$, von unten durch $\int_{1}^{\infty} \frac{1}{x} dx$ abschätzen, dann divergent.
	\item $\int_1 ^\infty \sin^2\left(\frac{1}{x}\right) dx$, beachte dass wenn $x \geq 0$, $\sin(x) \leq x$ gilt. Somit haben wir Majorante $\int_{1}^{\infty} \frac{1}{x^2} dx$ und konvergent. 
\end{itemize}


\subsection*{Absolute Konvergenz}
$$ \int_{a}^{\infty} \left| f(x) \right| dx <\infty \implies \int_{a}^{\infty}f(x) dx < \infty $$
Das ist nützlich bei trigonometrischen Teilen.\\
\textbf{Beispiel (Absolute Konvergenz)} 
\begin{itemize}
	\item $\int_{1}^{\infty} \frac{\cos^2(x)}{x^2} dx$. Es gilt $\left| \frac{\cos^2(x)}{x^2}\right|\leq \frac{1}{x^2}$, somit konvergent.
	\item $\int_0 ^\infty x\sin(4x)e^{-2x} dx$. Es gilt $|x\sin(4x)e^{-2x}| \leq xe^{-2x}$ wenn $x\geq 0$, per partieller Integration konvergiert das zweite. Somit konvergent.
\end{itemize}

\subsection*{Mc. Laurin Konvergenzkriterium}
Sei $f:[1,\infty) \to [0,\infty)$ monoton fallend.
$$\sum_{n=1}^{\infty} f(n) \ \text{konv.}  \iff    \int_{1}^{\infty} f(x) dx \ \text{konv.}$$



\vfill\null
\columnbreak

% to have more vertical space in the table.

{\renewcommand{\arraystretch}{1.5}
	\begin{table}[]
		\begin{tabular}{@{} p{.25\textwidth} p{.3\textwidth} p{.45\textwidth} @{}}
			\toprule
			Funktion & Ableitung & Bemerkung / Regel\\ \midrule
			$x$ & $1$ &   \\
			$x^2$& $2x$ &   \\
			$x^n$& $n\cdot x^{n-1}$ & $n \in \R$  \\
			$\frac{1}{x} = x^{-1}$ & $- \frac{1}{x^2}$ & \\
			$\sqrt{x} = x^{\frac{1}{2}}$ & $\frac{1}{2\sqrt{x}}$ & \\ 
			$\sqrt[n]{x} = x^{\frac{1}{n}}$ & $\frac{x^{\frac{1}{n} -1 }}{n}$ &  $\int x^{1/n} dx = \frac{n x^{1/n + 1}}{n+1} + C$\\ 
			$e^x$ & $e^x$ & \\
			$a^x$ & $\ln(a) \cdot a^x$& \\
			$x^x = e^{x\log(x)}$ & $x^x \cdot (\log(x) + 1)$ & Kettenregel $e^{x\log(x)}$\\
			$\ln(x)$ & $\frac{1}{x}$ & \\
			$x\ln(x) - x$ & $\ln(x)$ &  \\ \midrule
			$\sin(x)$ & $\cos(x)$ & \\
			$\cos(x)$ & $- \sin(x)$ & \\ 
			$\tan(x) = \frac{\sin(x)}{\cos(x)}$ & $\frac{1}{\cos^2(x)} = 1 + \tan^2(x)$ &\\
			$\cot(x) = \frac{\cos(x)}{\sin(x)}$ & - $\frac{1}{\sin^2(x)}$ & \\ 
			$\arcsin(x)$ & $\frac{1}{\sqrt{1 - x^2}}$ & $ \arcsin : [-1,1] \to [-\frac{\pi}{2},\frac{\pi}{2}]$\\
			$\arccos(x)$ & $ - \frac{1}{\sqrt{1-x^2}}$ & $\arccos : [-1,1] \to [0, \pi]$\\
			$\arctan(x)$ & $\frac{1}{1+x^2}$ & $\arctan:(-\infty, \infty) \to (- \frac{\pi}{2},\frac{\pi}{2})$\\
			$\operatorname{arccot}(x)$ & $ - \frac{1}{1+x^2} $ & $\operatorname{arccot} : (-\infty, \infty) \to (0,\pi)$\\
			\midrule
			$\cosh(x)$ & $\sinh(x)$ &\\
			$\sinh(x)$ & $\cosh(x)$ & \\
			$\tanh(x)$ & $\frac{1}{\cosh^2(x)}$ & \\
			$\operatorname{arsinh}(x)$ & $\frac{1}{\sqrt{1+x^2}}$ & $\forall x \in R$\\
			$\operatorname{arcos}(x)$ & $\frac{1}{\sqrt{x^2 - 1}}$ & $\forall x \in (1, \infty)$\\		  $\operatorname{artanh}(x)$ & $\frac{1}{1-x^2}$ & $\forall x \in (-1,1)$\\
			\midrule
			$g(x) \cdot h(x)$ & $g(x) \cdot h'(x) + g'(x) \cdot h(x)$ & Produktregel\\
			$\left(g(x)\right)^n$ & $n \cdot \left( g(x) \right)^{n-1} \cdot g'(x)$ & Potenzregel\\
			$\frac{g(x)}{h(x)}$ & $\frac{ g'(x) \cdot h(x) - g(x)\cdot h'(x)}{\left(h(x)\right) ^2}$ & Quotientenregel\\
			$h(g(x))$ & $h'(g(x)) \cdot g'(x)$ & Kettenregel\\
			\bottomrule
		\end{tabular}
	\end{table}
}




%----------------------------

%                      _           _       ___  
%    /\               | |         (_)     |__ \ 
%   /  \   _ __   __ _| |_   _ ___ _ ___     ) |
%  / /\ \ | '_ \ / _` | | | | / __| / __|   / / 
% / ____ \| | | | (_| | | |_| \__ \ \__ \  / /_ 
%/_/    \_\_| |_|\__,_|_|\__, |___/_|___/ |____|
%                         __/ |                 
%						  |___/                  

%----------------------------


\section*{Differentialgleichungen}







\subsection*{Differenzialgleichungen erster Ordnung}


\begin{method}{Trennung der Variablen} Wenn wir eine ODE der Form $y' = h(x)g(y) + b(x)$ haben so lösen wir das homogene Problem $y' = h(x)g(y)$ mittels Trennung der Variablen.
	
Sei nun somit $y' = \frac{dy}{dx} = h(x)\cdot g(y)$ so schreiben wir es als 

\begin{align*}
	\frac{dy}{g(y)} &= h(x)dx\\
	\int \frac{dy}{g(y)} &= \int h(x)dx
\end{align*}
um, was wir dann nach $y$ auflösen können.
\end{method}




\begin{method}{Variation der Konstanten (1te Ord.)} Wenn wir eine ODE der Form $y' = h(x)y + b(x)$ haben, so gilt dass $y(x) = y_{hom} + y_{part}$
\begin{itemize}
	\item \textbf{Schritt 1: } Löse homogenes Problem mittels Trennung der Variablen
	\item \textbf{Schritt 2: } Die Integrationskonstante $C$ aus Schritt 1 fassen wir als eine von $x$ abhängige Funktion $C(x)$ auf.
	\item \textbf{Schritt 3: } Die enstandene Funktion $y_p(x)$, die homogene Lösung mit $C(x)$ anstatt $C$ setzte als Ansatz in die Differentialgleichung ein und löse nach $C(x)$ ein. Dies gibt die partikuläre Lösung.
	\item \textbf{Schritt 4: } Setzte $y(x) = y_h(x) + y_p(x)$.
\end{itemize}
	
\end{method}

\begin{method}{Variation der Konstanten (1te Ord.)} Wenn wir eine ODE der Form $y' = h(x)y + b(x)$ haben, so gilt dass $y(x) = y_{hom} + y_{part}$
	\begin{itemize}
		\item \textbf{Schritt 1: } Löse homogenes Problem mittels Trennung der Variablen
		\item \textbf{Schritt 2: } Die Integrationskonstante $C$ aus Schritt 1 fassen wir als eine von $x$ abhängige Funktion $C(x)$ auf.
		\item \textbf{Schritt 3: } Die enstandene Funktion $y_p(x)$, die homogene Lösung mit $C(x)$ anstatt $C$ setzte als Ansatz in die Differentialgleichung ein und löse nach $C(x)$ ein. Dies gibt die partikuläre Lösung.
		\item \textbf{Schritt 4: } Setzte $y(x) = y_h(x) + y_p(x)$.
	\end{itemize}
	
\end{method}


\textbf{Beispiel $(\sin(x))y' = (\cos(x))y = e^x$}. Zuerst homogen:
\begin{align*}
(\sin(x))y' = (\cos(x))y &\Rightarrow \frac{dy}{dx} = - \frac{\cos(x)}{\sin(x)}y. \text{ check nicht } f=0\\	
\frac{dy}{y} = \frac{\cos(x)}{\sin(x)}dx &\Rightarrow \log|y| = -\log|\sin(x)| + C\\
y_{hom}= \frac{C}{\sin(x)}
\end{align*}
Nun partikul. $y_p = \frac{C(x)}{\sin(x)}$
\begin{align*}
\sin(x) \left(\frac{C'}{\sin(x)} - \frac{C\cos(x)}{\sin^2(x)}\right) + \cos(x)\frac{C}{\sin(x)} &= e^x\\
C' = e^x \Rightarrow C(x) = e^x &\Rightarrow y_p = \frac{e^x}{\sin(x)}
\end{align*}
Dies gibt $y(x) = \frac{C}{\sin(x)} + \frac{e^x}{\sin(x)}$



\begin{method}{Variation der Konstanten (2te Ord.)} Wir haben eine ODE der Form $y'' + a_1 y' + a_0 y = g(x)$:
	\begin{itemize}
		\item \textbf{Schritt 1: } Löse homogenes Problem mittels Euleransatz
		\item \textbf{Schritt 2: } Suche nun eine Lösung der Form $y_p(x) = C_1 (x)y_1 (x) +c_2(x)y_2(x)$ wobei $y_1$ und $y_2$ aus dem Euler Ansatz kommen und das System  $\left\{
		\begin{array}{ll}
		C_1'(x) y_1(x) + C_2'(x)y_2(x) = 0 \\
		C_1'(x) y_1'(x) + C_2'(x)y_2'(x) = g(x)
		\end{array}
		\right.$ erfüllt sein muss. Dafür darf Determinante des Systems nicht verschwinden. Sonst keine eindeutige Lösung.
		\item \textbf{Schritt 3: } Nun finden wir $C_1$ und $C_2$ durch 
		\begin{align*}
			\begin{pmatrix}
			C_1'(x)\\C_2'(x)
			\end{pmatrix} &= \frac{1}{y_1(x) y_2'(x) - y_2(x) y_1'(x)} 	\begin{pmatrix}
			-y_2(x) g(x)\\ y_1(x) g(x)
			\end{pmatrix} 
		\end{align*}
		\item \textbf{Schritt 4: } Finde $C_1 = \int C_1' dx$ sowie $C_2$. Dann baue $y_p(x) = C_1 (x)y_1 (x) +C_2(x)y_2(x)$.
		\item \textbf{Schritt 5: } Setzte $y(x) = y_h(x) + y_p(x)$.
	\end{itemize}
	
\end{method}


\subsection*{Lineare DGL $n$-ter Ordnung}

Wir lösen das homogene Problem vor dem inhomogenen!

\begin{method}{Homogene Lineare DGL $n$-ter Ordnung}

Wenn wir eine Gleichung der Form
\begin{align*}
a_ny^{(n)} + a_{n-1}y^{(n-1)} + \ldots + a_0 y &= 0
\end{align*}
dann nehmen wir den Euler-Ansatz $y(x) = e^{\lambda x}$ und finden $\lambda$ mit
\begin{align*}
a_n \lambda^n + a_{n-1}\lambda^{n-1} + a_0 &= 0
\end{align*}
Nun finden wir die Nullstellen $\lambda$ des charakteristischen Polynoms. Wir bauen uns nun eine Basis aus $e^{\lambda_i x}$ Wenn eine Nullstelle $m$ mal Vorkommt nehmen wir
\begin{align*}
e^{\lambda x},e^{\lambda x}, \ldots , x^{m-1} e^{\lambda x} 
\end{align*}
Das gibt uns ein Fundamentalsystem. Die Allgemeine Lösung ist eine Linearkombination der Basis (basierend auf den Anfangswerten).
\end{method}

Wenn die NS $\lambda = \beta + i\gamma$ nicht reell ist, so ist (bei rellen DGL) auch $\beta -i\gamma$ auch eine NS. Wir konnen dann $e^{x(\beta + i\gamma)}$, $e^{x(\beta - i\gamma)}$ auswechseln durch $f_1 = e^{x\beta}\cos(\gamma x)$ sowie $f_2 = e^{x\beta}\sin(\gamma x)$ austauschen. Erinnere dass $e^\lambda x$


\textbf{Beispiel $y'' - 4y' + 13y = xe^x$} Mit dem Euler Ansatz kriegen wir $\lambda^2 - 4 \lambda + 13 = 0$. Dies gibt $y_{hom} = Ae^{(2+3i)x} + Ae^{(2-3i)x}$ wir nutzen aber $y_{hom} = e^{2x}(C\sin(3x) + D\cos(3x))$. Nun wollen wir $e^x(ax + b)$ als Ansatz für $y_p$ nehmen. Dann setzte ein und finde Konstanten $a,b$ mit Koeff.vergleich. Dann setzte $y = y_{hom} + y_p$. Also $y = e^{2x}(C\sin(3x) + D\cos(3x)) + \left(\frac{x}{10} + \frac{1}{50}\right)$.



\begin{method}{Direkter Ansatz nichthomogene DLG $n$-ter Ordnung}
	Für DLGs der Form $$a_n y^{(n)} + a_{n-1} y^{(n-1)} + \cdots + a_0 y = b(x)$$
	mit dem Euler Ansatz lösen wir das homogene Problem. Die partikuläre Lösung finden wir mit der Idee, dass $y_p(x)$ die slebe Form wie $b(x)$ hat.
	
	\includegraphics[width=\textwidth]{ansatz.png}
	
	Dabei gilt:
	\begin{itemize}
		\item Verschiedene Ansätze können kombiniert werden. So wählt man für $b(x) = 5x + \sin(x)2^{3x}$ als Ansatz $Ax+B + (C + \sin(x) + D\cos(x))e^{3x}$
		\item Wenn ein Teil der zu wählenden Funktion für $y_p(x)$ bereits in $y_h(x)$ drin ist, so Multipliziere den Ansatz mit $x$. So wählt man für $y_h(x) = Ax + B$ anstelle des Ansatzes $y_p(x) = Ax+B$ den Ansatz $y_p(x) = x(Ax + b)$
	\end{itemize}
\end{method}


\subsection*{Variabelwechsel}
Nutze eine Substitution und brauche dann die Methode des direkten Ansatzes:
\begin{itemize}
	\item $\boxed{y' = h\left(\frac{y}{x}\right)}$, setzte $z(x) = \frac{y(x)}{x}$ respektive $y(x) = xz(x)$, dann wird $y' = z+xz'$.
	\item $\boxed{y' = h(ax+by+c)}$, setzte $z(x) = ax + by(x)+c$, respektive $y = \frac{z-ax-c}{b}$, dann wird $y' = \frac{z' -a}{b}$.
	\item $\boxed{y' = h \left(\frac{ax+by+c}{dx+ey+f}\right) }$, Wir wollen $x,y(x)$ ersetzten, dafür lösen wir das Gleichungssystem $\left\{
	\begin{array}{ll}
	ax + by+c = 0 \\
	dx+ey+f 
	\end{array}
	\right.$, wir wollen eine Eindeutige Lösung $(x_0,y_0)$, desshalb fordern wir $\operatorname{det}\begin{pmatrix}
	a & b \\ d & e
	\end{pmatrix} \neq 0$, dann setzten wir $z = y-y_0$ sowie $t = x-x_0$, damit wird: $y' = \frac{dy}{dx} = \frac{d(z+y_0)}{d(t+x_0)} = \frac{dz}{dt} = z'$.
	\item $\boxed{y' = \frac{y}{x} h(xy)}$, setzte $z(x) = xy(x)$, respektive $y = \frac{z(x)}{x}$ dann wird $y' = \frac{xz' - z}{x^2}$.
\end{itemize}






\section*{Continuity in $\R^n$}
\begin{method}{Convergence of sequence in $\R^n$}
	Let $(x_n)_n$ be a sequence  in $\R^n$. We say that a sequence converges to $y$ if for all $\epsilon > 0$, there exists $N \geq 1$ such that for all $n \geq N$ we have $\norm{x_n-y}\leq \epsilon$
\end{method}

\begin{method}{Continuity in $\R^n$}
	\begin{itemize}
		\item 	Let $x_0\in X$, we say that $f$ is continuous at $x_0$ if for all $\epsilon> 0$, there exists $\delta > 0$ such that if $x\in X$ satisfies $\norm{x-x_0}<\delta$ then $\norm{f(x) -f(x_0)}<\epsilon$.
		\item The function $f:X\to \R^m$ is continuous at $x_0$ if and only if, for every sequence $(x_n)_n$ in $X$ such that $x_k\to x_0$ as $k \to \infty$ the sequence $(f(x_k))_k$ converges to $f(x_0)$
	\end{itemize}
\end{method}


\section*{Topology of $\R^n$}


\begin{method}{Bounded, Closed \& Compact}
	\begin{itemize}
		\item A subset $X\subseteq \R^n$ is bounded if the set is contained in a ball of finite radius. (Altern. if $\exists$ lower and upper bounds not in set).
		\item A subset $X \subseteq \in \R^n$ is closed if for every sequence $(x_k)_k$ in $X$ that converges to some $y\in \R^n$, we have $y \in X$.
		\item A subset $X \subseteq \R^n$ is compact if it is bounded and closed.
	\end{itemize}
\end{method}
\textbf{Examples:}
\begin{itemize}
	\item $\{(x,y) \in \R^2 | x^2 + y^2 < 2019\}$ is bounded but not closed since boundary not included.
	
	\item $\{ (a,b,c) \in \mathbb{Z}^3  | a^2 + b^2 + c^2 < 2019 \}$ is compact since finite.
	
	\item $\{(x,f(x)) \in \R^2  | x \in \left(0,1\right], f(x) = \sin\frac{1}{x} \}$ not closed since $(0,0)$ not contained but $(\frac{1}{2k\pi},0)$ is $\forall k$.
	
	\item $\{ (\cos\phi,\sin\phi) \in\R^2 | \phi \in \mathbb{Q} \}$ is not closed since $(1,1)$ can be approximated but never reached.
	
	\item $\{(x,y,z) \in \R^3 | x^2 + y^ + z^2 \leq 2 \}$ closed and bounded, hence compact.
\end{itemize}

\section*{Differentiability in $\R^n$}
It turns out that the existence of partial derivatives is not enough to show differentiability of a function. An example is the function $f(x,y) = \begin{cases} 
0 \ \text{ if } (x,y) = (0,0)\\
\frac{xy}{x^2+y^2} \ \text{ else}
\end{cases}$. Using the polar coordinate trick one can see that the function is not continuous, however both partial derivatives give $\partial_{x} f(0,0) = \partial_{y}f(0,0) = 0$, nevertheless, there exists no differential of $f$ at $(0,0)$ since it is not continuous there.
\begin{method}{Differentiable in $\R^n$}
	\begin{itemize}
		\item 	Let $X\subseteq \R^n$ be open and $f: X \to \R^n$ be a function. Let $u$ be a linear map $\R^n \to \R^m$ and $x_0 \in X$. We say $f$ is \textit{differentiable} at $x_0$ with differential $u$ if
		\begin{align*}
		\lim\limits_{\substack{x\to x_0 \\x \not = x_0}} \frac{1}{\norm{x-x_0}} (f(x) -f(x_0) - u(x-x_0) ) = 0
		\end{align*}
		where the limit is in $\R^n$. We then denote $df(x_0) = u$
		If $f$ is differentiable at every $x_0 \in X$, then we say that $f$ is differentiable on $X$.
		\item Let $X \subseteq \R^n$ open, $f:\ X \to \R^m$ a function on $X$: If:
		\begin{itemize}
			\item $f$ has all partial derivatives on $X$
			\item and if all the partial derivatives are continuous on $X$
		\end{itemize}
	then $f$ is differentiable on $X$, then the Jabobi matrix of $f$ at $x_0$ is $df(x_0)$ with respect to the canonical basis of $\R^n$
	\end{itemize}
\end{method}

\textbf{Examples}

\begin{itemize}
	\item \textbf{Show that $\frac{\partial^2 f}{\partial y \partial x}(0,0)$ and $\frac{\partial^2 f}{\partial y \partial x}(0,0)$ exist but are not equal with $f(0,0) = 0$ and $f(x,y) = \frac{xy(x^2-y^2)}{x^2 + y^2}$:}
	lalala
	
\end{itemize}
\TODO{...}


\textbf{Example (Total Differentiability)}
Let $f(0,0) = 0$ and $f(x,y) = \frac{x^2 y^2}{x^2+y^2}$ for $(x,y)\neq (0,0)$. Show that $f \in C^1$. We first show that $f$ is continuous at $(0,0)$, for this we use the polar coordinates trick:
\begin{align*}
	\lim\limits_{(x,y)\to(0,0)} \frac{x^2 y^2}{x^2+y^2} &= \lim\limits_{r\to 0} \frac{r^4 \sin^2(\phi)\cos^2(\phi)}{\sin^2(\phi) + \cos^2(\phi)} = 0
\end{align*}

As a second step we show differentiability at $(0,0)$: We will use two methods:

\textbf{Direct Method:}
We calculate the Jacobi Matrix at $(0,0)$ and plug it into the definition of differentability:
\begin{align*}
	\frac{\partial f}{\partial x}(0,0) &= \lim\limits_{h \to 0}\frac{f(0+h,0) -f(0,0)}{h} = \lim\limits_{h \to 0} \frac{\frac{0h^2}{h^2 + 0} - 0}{h} = 0\\
	\frac{\partial f}{\partial y}(0,0) &= \lim\limits_{h \to 0}\frac{f(0,0+h) -f(0,0)}{h} = \lim\limits_{h \to 0} \frac{\frac{h^2 0}{0+h^2} - 0}{h} = 0
\end{align*}
Hence we have $J_f (0,0) = \left[0,0\right]$. Now we calculate:
\begin{align*}
&\lim\limits_{\substack{(x,y)\to (0,0)}} \frac{\left(f\left(\begin{pmatrix}
	x \\ y
	\end{pmatrix}\right) -f\left(\begin{pmatrix}
	0 \\ 0
	\end{pmatrix}\right) - J_f(0,0)\begin{pmatrix}
	x-0 \\ y -0
	\end{pmatrix}\right)}{\norm{\begin{pmatrix}
		x -0 \\ y -0
		\end{pmatrix}}} \\
	&= \lim\limits_{\substack{(x,y)\to (0,0)}} \frac{\frac{x^2 y^2}{x^2 + y^2} - 0 - \left[0,0\right] \begin{pmatrix}
x-0 \\ y -0
\end{pmatrix}}{ \sqrt{x^2 + y^2} }\\
&= \lim\limits_{\substack{(x,y)\to (0,0)}} \frac{\frac{x^2 y^2}{x^2 + y^2}}{ \sqrt{x^2 + y^2} }\\
&=  \lim\limits_{\substack{r \to 0}} \frac{r^4 \sin^2(\phi) \cos^2(\phi) }{r^3} = 0
\end{align*}
Since this fulfills the definition $f$ is differentiable in all of $\R^2$.

\textbf{Direct Method:} Via partial derivatives:

\begin{align*}
	\frac{\partial f}{\partial x} &= \frac{2xy^2}{x^2 +y^2} - \frac{2x^3 y^2}{(x^2+y^2)^2}\\
	\frac{\partial f}{\partial y} &= \frac{2x^2y}{x^2 +y^2} - \frac{2x^2 y^3}{(x^2+y^2)^2}\\
\end{align*}
We now calculate $\lim\limits_{(x,y)\to(0,0)} \frac{\partial f}{\partial x}$ and  $\lim\limits_{(x,y)\to(0,0)} \frac{\partial f}{\partial y}$ using the polar coordinates trick and get the same result as above. 


\subsection*{Rules for differentiation in $\R^n$}

\begin{method}{Directional Derivative}
	Let $f:X\subseteq \R^n$, the directional derivative $w$ in direction $v$ at $x_0$ is defined by the derivative of $g(t) = f(x_0+t\cdot v)$ at $t = 0$. 
	
	We have \begin{align*}
		D_u f(a) &= \frac{d}{dt} (f(a+tu))_{|t=0}\\
		D_u f(a) &= df(a) \cdot u
	\end{align*}
\end{method}
\textbf{Examples:}
We would like to find $D_u f((0,1))$ in direction $\frac{1}{\sqrt{17}}(-1,4)$ of the function $f(x,y) = e^{-x} \log(y)$:
\begin{itemize}
	\item \textsc{Using the definition:} We find $f(a+tu) = e^{\frac{t}{\sqrt{17}}} \log\left(1 + \frac{4t}{\sqrt{17}}\right)$ By diff: $D_u f(a) = \lim\limits_{t \to 0} \frac{e^{\frac{t}{\sqrt{17}}}}{\sqrt{17}} \log\left(1 + \frac{4t}{\sqrt{17}}\right) + \frac{4e^{\frac{t}{\sqrt{17}}}}{\sqrt{17}(1 + \frac{4t}{\sqrt{17}})} = \frac{\log(1) + 4}{\sqrt{17}} = \frac{4}{\sqrt{17}}$
	
	
	\item \textsc{Using the total derivative:} We known $D_u f(a) = df(a) \cdot u$, we get $df(x,y) = (-e^{-x}\log(y), \frac{e^{-x}}{y})$ hence $df(0,1) = (0,1)$. By multiplication we get $\frac{1}{\sqrt{17}}(-1,4) \cdot (0,1) = \frac{4}{\sqrt{17}}$.
\end{itemize}



\begin{method}{Gradient Vector}
	If $f:X\subseteq \R^n \to \R$ then we define $\nabla f(x_0)$:
	\begin{align*}
		\nabla f(x_0) &= 	\begin{pmatrix}
		\partial_{x_1} f(x_1)\\
		\ldots\\
		\partial_{x_n} f(x_0)
		\end{pmatrix}
	\end{align*}
\end{method}

\begin{method}{Jacobi Matrix}
	If $f(x) = (f_1(x),\ldots f_m(x))$ then we define
	\begin{align*}
		J_f(x) = \begin{pmatrix}
		\frac{\partial f_1}{\partial x_1}(x) & \ldots & \frac{\partial f_1}{\partial x_n}(x) \\
		\vdots & \ddots & \vdots \\
		\frac{\partial f_m}{\partial x_1}(x) & \ldots & \frac{\partial f_m}{\partial x_n}(x)	
		\end{pmatrix}
	\end{align*}
\end{method}

\begin{method}{Chain Rule}
	We have 
	\begin{align*}
		d(g \circ f)(x) &= d(g(f(x)) = dg(f(x))\cdot df(x)\\
		J_{g\circ f}(x) &= J_{g}(f(x)) \cdot J_{f} (x)
	\end{align*}
	The order of the matrices is IMPORTANT.
\end{method}
\textbf{Example}
\begin{itemize}
	\item Let $f(x,y,z)\mapsto (xy,y+z)$ and $g(x,y) \mapsto (e^x,xy)$.
	We have $dg(x,y) = \begin{pmatrix}
	e^x & 0 \\ y & x
	\end{pmatrix}$ as well as $df(x) = \begin{pmatrix}
	y & x & 0 \\ 0 & 1 & 1
	\end{pmatrix}$. From $dg$ we can find $dg(f) = \begin{pmatrix}
	e^{xy} & 0 \\ y+z & xy
	\end{pmatrix}$ This gives us for $d(g(f(x))) = dg(f(x))\cdot df(x)$:
	\begin{align*} \begin{pmatrix}
	e^{xy} & 0 \\ y+z & xy
	\end{pmatrix} \cdot \begin{pmatrix}
	y & x & 0 \\ 0 & 1 & 1
	\end{pmatrix} = 
	\begin{pmatrix}
	ye^{xy} & xe^{xy} & 0 \\ y^2+yz & 2xy +zx & xy
	\end{pmatrix}
	\end{align*}
	
	\item Let $f(x,y)\mapsto (e^x + \sin(xy), x+y^2x)$ and $g = f\circ f \circ f$. Find $dg(0,0)$: We have first notice that:
	\begin{align*}
		f(0,0) &= \begin{pmatrix}
		e^0 + \sin(0\cdot 0) & 0 + 0^2\cdot 0
		\end{pmatrix} = \begin{pmatrix}
		1 & 0
		\end{pmatrix}\\
		f(f(0,0)) &= f(1,0) = \begin{pmatrix}
		e^1 + \sin(1\cdot 0) & 1 + 0^2\cdot 1
		\end{pmatrix} = \begin{pmatrix}
		e & 1
		\end{pmatrix}
	\end{align*}
	Now we can use these results:
	\begin{align*}
		df(x,y) &= \begin{pmatrix}
		e^{x} + y\cos(xy) & x\cos(xy) \\1+y^2 & 2xy
		\end{pmatrix}\\
		df(0,0) &= \begin{pmatrix} 1 & 0 \\ 1 & 0
		\end{pmatrix}\\
		df(f(0,0)) &= df(1,0) = \begin{pmatrix}
		e & 1 \\ 1& 0
		\end{pmatrix}\\
		df(f(f(0,0))) &= df(e,1) =  \begin{pmatrix}
		e^e + \cos(e) & e\cos(e) \\ 2 & 2e
		\end{pmatrix}
	\end{align*}
	We can now insert these results: (calculating matrix product omitted)
	\begin{align*}
		dg(0,0) &= df(f(f(0,0)))\cdot df(f(0,0)) \cdot df(0,0) \\
		&= df(e,1) \cdot df(1,0)\cdot df(0,0)
	\end{align*}
\end{itemize}

\begin{method}{Tangential Plane via Definition}
	Wir wollen die Tangentialebene am Punkt $(x_0,y_0)$ der Fläche $f(x,y)$ finden. 
	\begin{itemize}
		\item Definiere $F(x,y) = (x,y,f(x,y))$ und berechne $$dF(x_0,y_0) = \begin{pmatrix}
\frac{\partial F_1}{\partial x} (x_0,y_0) & \frac{\partial F_1}{\partial y} (x_0,y_0)\\
\frac{\partial F_2}{\partial x} (x_0,y_0) & \frac{\partial F_2}{\partial y} (x_0,y_0)\\
\frac{\partial F_3}{\partial x} (x_0,y_0) & \frac{\partial F_3}{\partial y} (x_0,y_0)
		\end{pmatrix} = \begin{pmatrix}
		u_1 & v_1 \\ u_2 & v_2 \\ u_3 & v_3 
		\end{pmatrix}$$
		\item Nun berechnen wir den Normalenvektor $n = u \times v$
		$$\begin{pmatrix}
		u_1\\u_2\\u_3
		\end{pmatrix} \times \begin{pmatrix}
		v_1\\v_2\\v_3
		\end{pmatrix} = \begin{pmatrix}
		a \\ b \\ c
		\end{pmatrix}$$
		Nun berechnen wir $d$ mit $p = (x_0,y_0,f(x_0,y_0))$ mit $d=p\cdot n$
		\item Zum Schluss fassen wir die Gleichung zu $ax + by + cz = d$ zusammen.
	\end{itemize}
\end{method}

\begin{method}{Tangential Plane via Taylor Approximation}
	Wir approximieren $f$ im Punkt $(x_0,y_0)$ durch ein Taylorpolynom ersten Grades:
	$$z = f(x_0,y_0) + \frac{\partial f}{\partial x} (x_0,y_0) \cdot (x-x_0) + \frac{\partial f}{\partial y} (x_0,y_0) \cdot (y-y_0)$$
\end{method}


\textbf{Example:}
Determine a constant $c\in\R$ such that the vector $(c,0,1)^T$ is perpendicular to the surface of $\mathcal{G}(f)$ at the point $(\frac{\pi}{2},0,1)\in\mathcal{G}(f)$ with $f(x,y) = \sin(x) -y^3 + y^2$. We see that $$dF(x_0,y_0) = \begin{pmatrix}
1 & 0 \\
0 & 1 \\
0 & 0
\end{pmatrix} = \begin{pmatrix}
u_1 & v_1 \\ u_2 & v_2 \\ u_3 & v_3 
\end{pmatrix}$$ with $v$ and $u$ basis vectors of the tangential plane. Since we are looking for perpend. to surface we get $\begin{pmatrix}
	1 \\0 \\ 0 
\end{pmatrix} \times \begin{pmatrix}
0 \\ 1 \\ 0 
\end{pmatrix} = \begin{pmatrix}
0 \\ 0 \\ 1
\end{pmatrix}$. hence $c = 0$.



\begin{method}{Hessian}
	For the twice differentiable function $f: \Omega \subset \R^n \to \R$, the Hessian is defined as:
	\begin{align*}
	\begin{pmatrix}
	\frac{\partial ^2 f}{\partial x_1 ^2}(x) &\cdots &\frac{\partial ^2 f}{\partial x_1  \partial x_n}(x)\\
	\vdots & \ddots & \vdots \\
	\frac{\partial ^2 f}{\partial x_n \partial x_1}(x) &\cdots &\frac{\partial ^2 f}{\partial x_n ^2}(x)
	\end{pmatrix}
	\end{align*}
\end{method}

\begin{method}{Satz von Schwarz}
	Ist $f$ zweimal stetig partiell Ableitbar so gilt $\frac{\partial ^2 f}{\partial x \partial y} = \frac{\partial ^2 f}{\partial y \partial x} $
\end{method}

\begin{method}{Minimum / Maxinmum finden:}
	\begin{itemize}
		\item \textbf{Schritt 1:} Berechne Gradient und setzte null. $\nabla \cdot f = df = 0$, diese Punkte nennen wir critical points.
		\item \textbf{Schritt 2:} Berechne $\operatorname{Hess}(x_0)$:\begin{itemize}
			\item $\operatorname{Hess}(x_0)$ pos. def. dann $x_0$ lokales Minimum
			\item $\operatorname{Hess}(x_0)$ neg. def. dann $x_0$ lokales Maximum
			\item $\operatorname{Hess}(x_0)$ indef. dann $x_0$ Sattelpunkt
		\end{itemize}
	\end{itemize}
\end{method}

\begin{method}{Definitheit}
	Dabei sind $A_1, \ldots, A_n $ die Hauptminoren der Matrix.
	\begin{itemize}
		\item \textbf{Positiv Definit} Alle Eigenwerte strikt grösser als $0$, $A_1 > 0 , A_2 > 0, A_3 > 0, \ldots $
		\item \textbf{Negativ Definit} Alle Eigenwerte strikt kleiner als $0$, $A_1 < 0, A_2 > 0, A_3 < 0,\ldots$
	\end{itemize}
\end{method}
Dabei ist \begin{align*}
	A_1 &= \operatorname{det}\begin{pmatrix}
	a_{11}
	\end{pmatrix} &  A_2 &= \operatorname{det}\begin{pmatrix}
	a_{11} & a_{12} \\ a_{21} & a_{22}
	\end{pmatrix}
\end{align*}


\subsection*{Change of Variable}


\TODO{change of variable \& abuse of notation}


\section*{Taylor Approximation in $\R^n$}


\begin{method}{Taylor Approximation in $\R^n$}
	Let $k\in \N_{\geq 1}$ and $f:X \to \R  \in C^k$ on $X$, and fix $x_0 \in X$. The $k$-th order Taylor polynomial in $n$ variables of degree $\leq k$ is given by
	\begin{align*}
		T_k f(y;x_0) &= f(x_0) + \sum_{i=1}^{n} \frac{\partial f}{\partial x_i} (x_0) y_i + \ldots \\ & + \sum_{m_1 + \ldots + m_n = k}  \frac{1}{m_1 ! \cdots m_n !} \frac{\partial ^k f}{\partial_{x_1}^{m_1} \cdots \partial_{x_n}^{m_n} } (x_0) y_{1}^{m_1} \cdots y_{n}^{m_n}
	\end{align*}
	This simplifies to
	\begin{align*}
		T_{k} f(y;x_0) &= \sum_{|m|\leq k} \frac{1}{m!} \partial^{m}_{x} f(x_0) y^m
	\end{align*}
	Where we have used multi index notation with $|m| = m_1 + \ldots + m_n$ and $y^m = y_{1}^{m_1} \cdots y_{n}^{m_n}$\\
	
	Alternatively also directly:
	\begin{align*}
		  T_2f(\vec{x},\vec{a}) &= f(\vec{a}) + Df(\vec{a}) (\vec{x}-\vec{a}) +  \frac{1}{2} (\vec{x}-\vec{a})^T Hf(\vec{a}) (\vec{x}-\vec{a})
	\end{align*}
	
\end{method}


We have: (using the convention $\Delta x = x-x_0$ and $\Delta y = y-y_0$)

\begin{align*}
	&f(x,y) = f(x_0,y_0) + \frac{\partial f}{\partial x} \Delta x + \frac{\partial f}{\partial y} \Delta y\\
	&+ \frac{1}{2}\left(  \frac{\partial^2 f}{\partial^2 x} (\Delta x)^2  +  2\frac{\partial^2 f}{\partial x \partial y} \Delta x \Delta y +     \frac{\partial^2 f}{\partial^2 y} (\Delta y)^2   \right)\\
	&+ \frac{1}{3!}\left(    \frac{\partial^3 f}{\partial^3 x} (\Delta x)^3    + 3\frac{\partial^3 f}{\partial^2 x \partial y } (\Delta x)^2 \Delta y  +3\frac{\partial^3 f}{\partial x \partial^2 y } \Delta x (\Delta y)^2 +  \frac{\partial^3 f}{\partial^3 y} (\Delta y)^3 \right) 
\end{align*}



\begin{important}
If possible use $1$-dimensional Taylor series as starting point!
\end{important}

\textbf{Gerechnetes Beispiel $f(x,y,z) = e^{x,y,z}$}. Wir wollen zweite Ordnung in $(0,0,0)$
\begin{align*}
	T_2 f(x,(0,0,0)) &= f(0,0,0) + x\frac{\partial f}{\partial x} (0,0,0) + y\frac{\partial f}{\partial y} (0,0,0) +  z\frac{\partial f}{\partial z} (0,0,0)\\
	&+ \frac{1}{2} \biggl( x^2\frac{\partial^2 f}{\partial x^2} (0) + y^2\frac{\partial^2 f}{\partial y^2} (0) + z^2\frac{\partial^2 f}{\partial z^2} (0)  \\
	&+ 2xy \frac{\partial^2 f}{\partial x \partial y} 0 + 2yz \frac{\partial^2 f}{\partial y \partial z} 0 + 2xz \frac{\partial^2 f}{\partial x \partial z} 0 \biggr) + \ldots 
\end{align*}


\textbf{Use $1$-Dimensional Taylor Approximation}
\begin{itemize}
	\item \textbf{Find the fourth order Taylor approximation of $f(x,y) = \cos(x)\cdot \frac{1}{1-y^2}$ at $(0,0)$:} Recall that
	\begin{align*}
			\cos(x) &= 1 - \frac{x^2}{2} + \frac{x^4}{4!} - \ldots \\
			\frac{1}{1-y^2} &= 1 -y^2 + y^4 + \ldots 
	\end{align*}
	Hence we have:
	\begin{align*}
	f(x,y) &= \cos(x) \cdot \frac{1}{1-y^2} = \left( 1 - \frac{x^2}{2} + \frac{x^4}{4!} \right) \cdot \left( 1 -y^2 + y^4   \right)\\
	&= 1 - \frac{x^2}{2} - y^2 + \frac{x^2 y^2}{2} + \frac{x^4}{4!} + y^4 + \ldots
	\end{align*}
	
	
	
	\item \textbf{Find the Taylor series of $f(x,y) = \cos(xy)$ at $(0,0)$:} Recall that:
	\begin{align*}
		\cos(x) &= 1 - \frac{x^2}{2} + \frac{x^4}{4!} - \ldots = \sum_{n=0}^{\infty} \frac{(-1)^n x^{2n}}{(2n)!}
	\end{align*}
	We now replace $x$ by $xy$ and get
	\begin{align*}
	f(xy) &= \cos(xy) = \sum_{n=0}^{\infty} \frac{(-1)^n x^{2n} y^{2n}}{(2n)!}
	\end{align*}
\end{itemize}


% todo




\section*{Wegintegrale}

\begin{method}{Wegintegral}
	Sei $f:\Omega \subset \R^n \to \R^n$ ein stetig differenzierbares Vektorfeld und $\gamma:[a,b]\to \R^n$ eine stückweise stetig differenzierbare Kurve. Der Ausdruck
	
	\begin{align*}
		\int_\gamma f \cdot ds &:= \int_{a}^{b} f(\gamma(t)) \cdot \gamma'(t) dt
	\end{align*}
	heistt das Wegintegral von $f$ entlang $\gamma$. Da dies alles Vektoren sind ist die Multiplikation das Skalarprodukt.
	
	Es gilt $\gamma  \in C^1_{pw}$ wobei pw = piece wise.
\end{method}

\textbf{Parametrisieren von Wegen / Kurven}
\begin{itemize}
	\item \textbf{Parabel $y=x^2$}, ganz einfach als $\gamma(t)\mapsto (t,t^2)$
	\item \textbf{Ellipse mit $(x-3)^2+4y^2 = 4$}, schreibe als $a^2 + b^2 = r^2$ mit $a = r\cos(t)$ und $b = r\sin(t)$. In unserem Fall ist $a = x-3$, $b=2y$ sowie $r = 2$. Dies gibt die Parametrisierung $\gamma(t) \mapsto (3+2\cos(t),\sin(t))$
\end{itemize}




\begin{method}{Länge einer Kurve}
	Sei $\gamma$ eine reguläre Kurve $\gamma : [a,b]\to \R^n$ mit $t \mapsto \gamma(t)$ , dann ist die Länge von $\gamma$ gegeben durch $L(\gamma) = \int_{a}^{b} |\gamma'(t)| dt$. Der Betrag ist dabei die euklidische Norm.
\end{method}

\begin{method}{Rezept für Wegintegrale}
	Gegeben ein Vektorfeld $f \in C^1$ und eine Kurve $\gamma \in C^1_{pw}$, gesucht $\int_\gamma f\cdot ds$.
	\begin{itemize}
		\item \textbf{Schritt 1:} Parametrisiere $\gamma$, d.h. finde Abbildung $\gamma(t):[a,b]\to\R^n,t\mapsto\gamma(t)$
		\item \textbf{Schritt 2:} Berechne $\gamma'(t) = \frac{d}{dt} \gamma(t)$, jede Komponente einzeln ableiten.
		\item \textbf{Schritt 3:} Berechne Wegintegral durch $\int_\gamma f\cdot ds := \int_{a}^{b} f(\gamma(t)) \cdot \gamma' (t) dt$
	\end{itemize}
	
\end{method}


\begin{method}{Potenzialfeld}
	Ein Vektorfeld $v:\Omega\subset \R^n \to \R^n$ heisst Potenzialfeld, falls eine stetig differenzierbare Abbildung $\phi:\Omega \subset \R^n \to \R$ existiert so dass $v = \nabla \phi$. Wir nennen $\phi$ das Potential von $v$. Dabei ist wichtig:
	\begin{itemize}
		\item Das Potential ist nicht eindeutig: $\phi = \overline{\phi} + C$
		\item Sehr viele Vektorfelder lassen sich nicht als Gradienten eines skalaren Feldes schreiben.
	\end{itemize}
\end{method}

\begin{method}{Existenz eines Potentialfeldes}
	Ist $v : \Omega \subset \R^n \to \R^n$ ein Potentialfeld (d.h. $\exists \phi : \nabla \phi = v$), so gelten die Integrabilitätsbedingungen $\frac{\partial v_i}{\partial x_j} = \frac{\partial v_j}{\partial x_i}$ für $i\neq j$ , $i,j\in\{1,\ldots,n\}$. Wenn $\Omega$ sternförmig ist, so gilt auch die Umkehrung. d.h. wenn die Integrabilitätsbedinungen erfüllt sind so gibt es ein Potential.
	
	Folgende Aussagen sind äquivalent:
	
	\begin{itemize}
		\item $v$ ist konservativ
		\item $v$ ist ein Potentialfeld  (d.h. $\exists \phi : \nabla \phi = v$)
		\item Für alle geschlossenen Kurven $\gamma$ gilt $\int_\gamma v\cdot ds = 0$
		\item Das Integral $\int_\gamma v\cdot ds$ ist unabhängig vom Weg.
		\item $v$ erfüllt die Integrabilitätsbedingungen $\nabla \times v = 0$ in $\R^3$
	\end{itemize}
	
\end{method}


\ifx
\begin{method}{Conservative Vector Fields}
	 \begin{itemize}
	 	\item 	A vector field $f(x)$ is conservative if the value $\int_{\gamma} f(s)\cdot ds$ does not depend on $\gamma$. 
	 	\item $f(x)$ is conservative on an open set $X$ if there exists $g\in C^1$ on $X$ such that $f = \nabla g$.
	 	\item  $f(x) = (f_1(x),\ldots f_n(x))$ on $X$ star shaped is conservative if for any integers $i\neq j$ we have $\frac{\partial f_i}{\partial x_j} = \frac{\partial f_j}{\partial x_i}$. If $f$ is conservative this holds even if $X$ is not star shaped.
	 \end{itemize}	
\end{method}
\fi




\section*{Mehrdimensionale Integrale}

\begin{method}{Negligible subset}
	A subset $B \subset \R^n$ is called negligible if $\exists k \in \N$ and paremeterized $m_i$ sets $f_i:X_i \to \R^n$ such that $X\subset f_1(x_1) \cup \ldots \cup f_k(X_k)$.  A parameterized $m$-set in $\R^n$ $\approx$ $m$-dimensional subset of $R^n$.
\end{method}
\textbf{Examples:}

\begin{itemize}
	\item $\{(i,j,k)\in\R^3 | i,j,k\in\mathbb{Z} , i^2 + j^2 + k^2 < 2019\}$ is negligible since we can just build finitely many constant maps from $[0,1]$ to these finitely many distinct points.
	\item $\{(x,y,z)\in\R^3 | x+y+z=1 ,x,y\in\left[0,1\right]\}$ is also negligible since we just need the map $(x,y)\to (x,y,1-x-y)$ from $\left[0,1\right]\to\R^3$
\end{itemize}

\begin{method}{Satz von Fubini}
	Sei $Q=[a_1,b_1]\times \ldots \times [a_n,b_n]$ ein Quader und $f:Q\to \R$ mit $f\in C^0(Q)$ gegeben, so gilt:
	
	\begin{align*}
		\int_Q f(x) d\mu(x) &= \int_{a_1}^{b_1} dx_1 \ldots \int_{a_n}^{b_n} dx_n f(x_1,\ldots x_n)
	\end{align*}
	wobei wir die Integrationsreihenfolge Vertauschen dürfen.
\end{method}


\begin{method}{Normalenbereich}
	Die beschränkte Teilmenge $\Omega \subset \R^n$ heisst $y$ Normalenbereich, falls sich $\Omega$ wie folgt darstellen lässt:
	
	\begin{align*}
		\Omega &= \{(x,y)\in\R^2 | a \leq x \leq b, f(x)\leq y \leq g(x)\}
	\end{align*}
	wobei $f,g$ stetig sind.
	
	\includegraphics[width=\textwidth]{normBe.png}
	
	Selbstverständlich können wir über den Normalenbereich integriere und es gilt:
	
	\begin{align*}
		\int_\Omega F d\mu &= \int_{a}^{b} dx \int_{f(x)}^{g(x)} dy F(x,y)
	\end{align*}
	
	dabei werte immer das innere Integral zuerst aus.
\end{method}

\textbf{Beispiele}

\begin{itemize}
	\item $\{(x,y)\in\R^2 | y \geq 0 , x-y + 1 \geq 0 , x + 2y -4 \leq 0\}$ Wir bemerken dass $x\leq 4-2y$ und $x\geq y-1$, wir suchen eine obere Schranke für $y$, dafür muss $4-2y = y-1$ gelten. Demnach integrieren wir $\int_{0}^{\frac{5}{3}} \int_{y-1}^{4-2y} dx dy$
	\item 
	\TODO{check!!!}
	Wir definieren $A_1$ und $A_2$. Die Schnittpunkte sind bei $(\frac{1}{\sqrt{b}}, \sqrt{b})$ sowie $(\frac{1}{\sqrt{a}}, \sqrt{a})$. Demnach ist $\int_A d\mu = \int_{0}^{\sqrt{a}} \int_{\frac{y}{b}}^{\frac{y}{a}} dx dy + \int_{\sqrt{a}}^{\sqrt{b}} \int_{\frac{y}{b}}^{\frac{1}{y}} dx dy$
	\includegraphics[width=\linewidth]{serie13.png}
\end{itemize}





\subsection*{Substitution}

\begin{method}{Substitutionsregel}
	\begin{itemize}
		\item \textbf{$1$-dimensional:} Sei $f$ Riemann-integrierbar, so gilt für die Substitution $x = g(u)$ mit $dx = g'(u)du$ dass
		$$\int_{a}^{b} f(x) dx = \int_{g^{-1}(a)}^{g^{-1}(b)} f(g(u))g'(u)du$$
		\item \textbf{$n$-dimensional:} Sei $f$ Riemann-integrierbar auf $\Omega \subset \R^n$ und die Substitution $(x_1,\ldots,x_n) = \phi(u_1,\ldots,u_n)$ oder in Komponenten $	\begin{pmatrix}
x_1\\ \vdots\\x_n
		\end{pmatrix} = \phi(u) = 	\begin{pmatrix}
		g_1(u_1,\ldots,u_n)\\
		\vdots \\
		g_n(u_1,\ldots,u_n)
		\end{pmatrix}$ wobei $\phi$ ein $C^1$ Diffeomorphismus ist. Dann gilt
		\begin{align*}
			\int_\Omega &f(x_1,\ldots , x_n) dx_1\ldots dx_n \\ &= \int_{\overline{\Omega}} f(g_1(x_1),\ldots , g_n(x_n)) |\operatorname{det}(d\phi) | du_1\ldots du_n
		\end{align*}
		mit $\overline{\Omega} = \phi^{-1}(\Omega)$
	\end{itemize}
\end{method}


\subsection*{Koordinatentransformationen}

\textbf{Polarkoordinaten $\R^2$}

\begin{align*}
	x &= r\cos\phi  & 0 \leq &r < \infty & dxdy &= rdrd\phi\\
	y &= r\sin\phi  & 0 \leq &\phi < 2\pi & & 
\end{align*}


\textbf{Elliptische Koordinaten $\R^2$}

\begin{align*}
	x &= ar\cos\phi  & 0 \leq &r < \infty & dxdy &= abrdrd\phi\\
	y &= br\sin\phi  & 0 \leq &\phi < 2\pi & & 
\end{align*}


\textbf{Zylinderkoordinaten $\R^3$}

\begin{align*}
x &= r\cos\phi  & 0 \leq &r < \infty & dxdydz &= r dr d\phi dz\\
y &= r\sin\phi  & 0 \leq &\phi < 2\pi & & \\
z &= z  &   -\infty < &z < \infty & & 
\end{align*}

\textbf{Kugelkoordinaten $\R^3$}

\begin{align*}
x &= r\sin\theta\cos\phi  & 0 \leq &r < \infty & dxdydz&=r^2 \sin \theta drd\theta d\phi\\
y &=r\sin\theta\sin\phi  & 0 \leq &\theta < \pi & & \\
z &= r\cos\theta  &  0 \leq &\phi < 2\pi & & 
\end{align*}

\TODO{off centered ball}.

\begin{method}{Masse, Schwerpunkt}
	Sei $\Omega$ ein 2-dimensionales Gebiet mit Massendichte $\rho(x,y)$, welche die Massenverteilung auf $\Omega$ beschreibt.
	
	\begin{itemize}
		\item \textbf{Masse:} $M(\Omega) = \int_{\Omega} \rho(x,y) dx dy$
		\item \textbf{Schwerpunkt:} \begin{align*}x_s &= \frac{1}{M} \int_{\Omega} x\rho(x,y) dx dy \\ y_s &= \frac{1}{M} \int_{\Omega} y\rho(x,y) dx dy \end{align*}
	\end{itemize}
	 Die Masse von $\Omega$ ist dann
	 
	 Das Konzept geht analog für $n$ Dimensionen.
\end{method}



\begin{method}{Oberfläche}
	\begin{itemize}
		\item \textbf{$1$-dim:}  $\int_{a}^{b} \sqrt{a+f'(x)^2} dx$
		\item \textbf{$2$-dim:} $\int_{a}^{b} \int_{c}^{d} \sqrt{1 + (\partial_{x} f(x,y))^2 + (\partial_{y} f(x,y))^2} dx dy$
	\end{itemize}
\end{method}


\begin{method}{Rotationskörper}
	Sei $R = \{(x,y,z) \in \R^3 | a \leq z \leq b, x^2 + y^2 \leq f^2(z)  \}$, dann ist $\operatorname{Vol}(R) = \pi \int_{a}^{b} dz f^2(z)$
\end{method}


\section*{Integralsätze}

\begin{method}{Satz von Green}
	$\vec{v} = (v_1,v_2)$ ein stetiges Vektorfeld auf $\Omega \subset \R^2$ und $C\subset \R^2$ ein beschränkter Bereich mit Rand $\gamma = \partial C$ in $C_{pw}^1$ der sich nicht selbst schneidet (also called simple closed parameterized curve mit $\gamma(t)\not=\gamma(s)$ für $s\neq t$). Dann gilt:
	$$\int_{\gamma = \partial C} \vec{v} \cdot d\vec{s} = \int_{C} \left( \frac{\partial v_2}{\partial x} -  \frac{\partial v_1}{\partial y}\right)dxdy$$
\end{method}

\begin{method}{Flächen mit dem Satz von Green berechnen}
	Gegeben ein Gebiet $C\subset \R^2$ beschränkt mit $C_{pw}^1$ Rand $\partial C$, gesucht Fläche $F(C)$
	\begin{itemize}
		\item \textbf{Schritt 1:} Parametrisiere den Rand von $C$ mit einer Kurve $\gamma:[a,b]\to \R^2$, $t\mapsto \gamma(t)$. Die Parametrisierung muss in positiver Richtung sein, d.h. das Gebiet links der Kurve sein.
		\item \textbf{Schritt 2:} Berechne $\gamma'$
		\item \textbf{Schritt 1:} Wähle ein geeignetes Vektorfeld wie z.B: $\vec{v} = (0,x)$ oder $\vec{v} = (-y/2,x/2)$ oder $\vec{v} = (-y,0)$ und wende dafür den Satz von Green an: $F(C) = \int_{\gamma=\partial C} \vec{v}\cdot d\vec{s}$
	\end{itemize}
\end{method}




\begin{method}{Satz von Gauss-Ostrogradski}
	Sei $V$ ein beschränkter räumlicher Bereich mit Rand $\partial V \in C^1_{pw}$ gegeben. Sei das Vektorfeld $\vec{v}$ auf ganz $V$ definiert und stetig differenzierbar. Dann gilt:
	\begin{align*}
		\int_{\partial V} \vec{v} \cdot \vec{n} \ do &= \int_{V} \vec{\nabla} \cdot \vec{v} \ d\mu
	\end{align*}
	wobei $\vec{n}$ der Normalenvektor entlang $\partial V$ ist, $do$ das zweidimensionale Integrationselement über die Fläche und $d\mu$ das dreidimensionale Integrationselement über das Volumen.
\end{method}

\textbf{Intuitive Erklärung: } Ändert sich das Vektorfeld im Innern, so muss sich dies beim Einfluss und Ausfluss bemerkbar machen.


\subsection*{Oberflächenintegral}
\textbf{Parametrisierung einer Fläche $F$} ist ein Diffeomorphismus $$\phi:b \to \R^3, (u,v)\to\phi(u,v) = \begin{pmatrix}
x(u,v)\\y(u,v)\\z(u,v)
\end{pmatrix}$$ sodass $\phi(B) = F$ gilt. Wir definieren $\phi_u = \frac{\partial \phi}{\partial u}$ sowie 
$\phi_v = \frac{\partial \phi}{\partial v}$ und definieren den Normalenvektor $\vec{n}$:

$$\vec{n} = \pm \frac{\phi_u \times \phi_v}{|\phi_u \times \phi_v|}$$

\begin{method}{Oberflächenmass}
Das Flächenelement bezüglich der Parametrisierung $\phi$ ist 

$$do = |\phi_u \times \phi_v|dudv = |\operatorname{det}(d\phi)|dudv$$ Um die Oberfläche zu kriegen berechne $\int do$	
\end{method}

\ifx

\begin{important}
	Satz von Stokes und Pappus nicht Prüfungsrelevant!
\end{important}

\begin{method}{Satz von Stokes}
	Sei $\vec{v} = (v_1,v_2,v_3)$ ein stetig differenzierbares Vektorfeld auf $\Omega\subset \R^3$ und $C\subset \Omega$ eine offene Fläche durch die geschlossene Kurve $\gamma = \partial C$ in $C_{pw}^1$ berandet, dann gilt:
	$$\int_{\gamma = \partial C} \vec{v}\cdot d\vec{s} = \int_{C} (\vec{\nabla}\times \vec{v}) \cdot\vec{n} do$$ wobei $\vec{n}$ der nach aussen gerichtete Normalenvektor entlang $C$ ist und $do$ das zweidimensionale Integrationselement über die Fläche bezeichnet. Der Weg $\gamma$ muss positiv orientiert sein.
\end{method}

\fi









% -------------------------- Sonstiges --------------------------





\section*{Sonstiges}
\begin{method}{Binomialsatz}
	$\forall x,y \in \mathbb{C}$, $n \geq 1$ gilt:
	$$(x+y)^n = \sum_{k=0}^{n} \binom{n}{k}x^k y^{n-k}$$
\end{method}

\begin{method}{ABC / Mitternachtsformel}
	\begin{align*}
	\text{Gegeben: } & ax^2 + bx + c = 0\\
	\text{Lösung: } & x_{1,2} = \frac{-b \pm \sqrt{b^2 -4ac}}{2a}
	\end{align*}
\end{method}


\begin{method}{Logarithmus Regeln}
\begin{align*}
	 \log _{b}(x\cdot y) &= \log _{b}(x)+\log _{b}(y)\\
	 \log_{b} (M^k) &= k \cdot \log_b (M)
\end{align*}
\end{method}


\begin{method}{Summenformeln}
	\begin{align*}
	\sum _{{k=1}}^{n}k &= {\frac  {n(n+1)}{2}}\\
	\sum_{k=1}^n (2k-1) &= n^2\\
	\sum _{{k=1}}^{n}k^{2} &= {\frac  {n(n+1)(2n+1)}{6}}
	\end{align*}
\end{method}


\begin{method}{Gerade \& Ungerade Funktion}
	Eine Funktion heisst:
	\begin{itemize}
		\item \textsc{Gerade} wenn $f(-x) = f(x)$
		\item \textsc{Ungerade} wenn $f(-x) = - f(x)$
	\end{itemize}
	Dabei sind $f(x) = 1$, $f(x) = |x|$, $f(x)=x^2$, $f(x) = \cos(x)$ alles gerade Funktionen.\\
	Im Gegenzug sind $f(x) = sgn(x)$, $f(x) = x$, $f(x) = \tan(x)$, $f(x) = \sin(x)$ ungerade Funktionen.
\end{method}


\begin{method}{Injektiv}
	\begin{align*}
	&\forall x_1,x_2 \in M : f(x_1) = f(x_2) \implies x_1 = x_2\\
	\text{or }  &x_1 \not = x_2 \implies f(x_1) \not = f(x_2)
	\end{align*}
	\textbf{Surjektiv}
	\begin{align*}
	\forall y \in N \exists x \in M : y = f(x)
	\end{align*}
\end{method}

\textbf{Umkehrsatz - Beispiel} Zeige dass $x + e^x$ bijektiv von $\R$ auf $\R$ abbildet. Es gilt $f'(x) = 1 + e^x > 0$, somit ist $f$ streng monoton wachsend in $\R$ und Umkehrbar. Weil $\lim_{x \to -\infty} f(x) = - \infty$ und $\lim_{x \to \infty} f(x) = \infty$ ist $f$ bijektiv von $\R$ nach $\R$



\begin{method}{Kreuzprodukt}
	\begin{align*}
	\vec{a}\times\vec{b}=	\begin{pmatrix}a_1 \\ a_2 \\ a_3\end{pmatrix}
	\times
	\begin{pmatrix}b_1 \\ b_2 \\ b_3 \end{pmatrix} &=	\begin{pmatrix}
	a_2b_3 - a_3b_2 \\
	a_3b_1 - a_1b_3 \\
	a_1b_2 - a_2b_1
	\end{pmatrix}
	\end{align*}
\end{method}



\subsection*{Wichtige Integrale}

\begin{itemize}	
	
	\item ${\displaystyle \int \sin ^{2}{ax}\,dx={\frac {x}{2}}-{\frac {1}{4a}}\sin 2ax+C={\frac {x}{2}}-{\frac {1}{2a}}\sin ax\cos ax+C}$
	
	\item ${\displaystyle \int \sin ^{n}{ax}\,dx=-{\frac {\sin ^{n-1}ax\cos ax}{na}}+{\frac {n-1}{n}}\int \sin ^{n-2}ax\,dx\qquad {\mbox{(for }}n>0{\mbox{)}}}$
	
	\item ${\displaystyle {\begin{aligned}\int x^{n}\sin ax\,dx&=-{\frac {x^{n}}{a}}\cos ax+{\frac {n}{a}}\int x^{n-1}\cos ax\,dx\end{aligned}}}$
	
	\item ${\displaystyle \int \cos ^{2}{ax}\,dx={\frac {x}{2}}+{\frac {1}{4a}}\sin 2ax+C={\frac {x}{2}}+{\frac {1}{2a}}\sin ax\cos ax+C}$
	
	\item ${\displaystyle \int \cos ^{n}ax\,dx={\frac {\cos ^{n-1}ax\sin ax}{na}}+{\frac {n-1}{n}}\int \cos ^{n-2}ax\,dx\qquad {\mbox{(for }}n>0{\mbox{)}}}$
	
	\item ${\displaystyle {\begin{aligned}\int x^{n}\cos ax\,dx&={\frac {x^{n}\sin ax}{a}}-{\frac {n}{a}}\int x^{n-1}\sin ax\,dx\end{aligned}}}$
	
	
	
	
	
	\item ${\displaystyle \int (\sin ax)(\cos ax)\,dx={\frac {1}{2a}}\sin ^{2}ax+C}$
	
	\item ${\displaystyle \int (\sin ^{n}ax)(\cos ax)\,dx={\frac {1}{a(n+1)}}\sin ^{n+1}ax+C\qquad {\mbox{(for }}n\neq -1{\mbox{)}}}$
	
	\item ${\displaystyle \int (\sin ax)(\cos ^{n}ax)\,dx=-{\frac {1}{a(n+1)}}\cos ^{n+1}ax+C\qquad {\mbox{(for }}n\neq -1{\mbox{)}}}$
	
	\item $ {\displaystyle {\begin{aligned}\int (\sin ^{n}ax)(\cos ^{m}ax)\,dx&=-{\frac {(\sin ^{n-1}ax)(\cos ^{m+1}ax)}{a(n+m)}}\\&+{\frac {n-1}{n+m}}\int (\sin ^{n-2}ax)(\cos ^{m}ax)\,dx\qquad {\mbox{(for }}m,n>0{\mbox{)}}\end{aligned}}} $
	
	
\end{itemize}



\subsubsection*{typische Integrale}

\begin{itemize}
	\item $\int \frac{1}{x} \,dx = \ln |x|$
	\item $\int \frac{1}{x^2} \,dx = -\frac{1}{x}$
	\item $\int \frac{1}{x+a} \,dx = \ln |x+a|$
	\item $\int \ln(x) \,dx = x(\ln(x) - 1)$
	\item $\int \ln(ax + b) \,dx = \frac{(a x+b) \ln (a x+b)-a x}{a}$
	\item $\int \frac{1}{(x+a)^2} \,dx = - \frac{1}{x+a}$
	\item $\int \frac{1}{\sqrt{x}} \,dx = 2 \sqrt{x}$
	\item $\int \sqrt{1-x^2} dx = \frac{\arcsin(x) + x \sqrt{1-x^2}}{2} + C$
	\item $\int \frac{1}{ax+b} \,dx = \frac{1}{a} \ln |ax+b|$
	\item $\int \frac{1}{1 + x^2} \,dx = \frac{1}{2} \ln |1 + x^2|$
	\item $\int(ax + b)^n \,dx = \frac{(ax + b)^{n+1}}{(n + 1)a}, (n \neq -1)$
	\item $\int x(ax+b)^n \,dx = \frac{(ax + b)^{n+2}}{(n+2)a^2} -
	\frac{b(ax+b)^{n+1}}{(n+1)a^2}$
	\item $\int \frac{ax + b}{px + q} \,dx = \frac{ax}{p} + \frac{bp - aq}{p^2} \ln
	|pq+q|$
	\item $\int \frac{1}{a^2 + x^2} \,dx = \frac{1}{a} \arctan(\frac{x}{a})$
	\item $\int \frac{1}{a^2 - x^2} \,dx = \frac{1}{2a} \ln \left | \frac{a+x}{a-x}
	\right |$
	\item $\int \sqrt{x} \,dx = \frac{2}{3}\sqrt{x^3}$
	%mühsamer kerl der teilweise in prüfungen verwendet wird. Kann man über subsitution von x mit sin(u) lösen.
	\item $\int \sqrt{1-x^2} \,dx = \frac{1}{2}\left( x\sqrt{1-x^2}+\frac{1}{\sin(x)} \right)$
	\item $\int a^{xb + c} \,dx = \frac{a^{bx + c}}{b \log(a)}$
\end{itemize}

\subsubsection*{trionometrische Funktionen}
\begin{itemize}
	\item $\int \sin(ax) \,dx = -\frac{1}{a}\cos(ax)$
	\item $\int \cos(ax) \,dx = \frac{1}{a}\sin(ax)$
	\item $\int \sin(ax)^2 \,dx = \frac{x}{2} - \frac{sin(2ax)}{4a}$
	\item $\int \frac{1}{\sin^2 x} \,dx = -\cot x$
	\item $\int x \sin(ax) \,dx = \frac{\sin(ax)}{a^2} - \frac{x \cos(ax)}{a}$
	\item $\int \cos^2(ax) \,dx = \frac{x}{2} + \frac{\sin(2ax)}{4a}$
	\item $\int \frac{1}{\cos^2(x)} \,dx = \tan x$
	\item $\int \cos(ax) \,dx = \frac{\cos(ax)}{a^2} + \frac{x \sin(ax)}{a}$
	\item $\int \sin(ax) \cos(ax) \,dx = -\frac{\cos^2(ax)}{2a}$
	\item $\int \tan(ax) \,dx = - \frac{1}{a} \ln | \cos(ax) |$
\end{itemize}

\subsubsection*{Exponentialfunktion}
\begin{itemize}
	\item $\int e^{ax} \,dx = \frac{1}{a} e^{ax}$ 
	\item $\int x e^{ax} \,dx = e^{ax} \cdot \left ( \frac{ax - 1}{a^2} \right )$
	\item $\int x \ln(x) \,dx = \frac{1}{2} x^2 (\ln(x) - \frac{1}{2})$
	\item $\int_{-\infty}^\infty e^{-\frac{1}{a}x^2} \,dx = \sqrt{a \pi}$
\end{itemize}




\newpage

\end{multicols}
\end{document}
